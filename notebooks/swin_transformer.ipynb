{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import glob\n",
    "import PIL, cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "sys.path.append('../scripts/')\n",
    "sys.path.append('../scripts/helper_functions_cv/tensorflow_helpers/')\n",
    "from save_weights_every_epoch import CallbackForSavingModelWeights\n",
    "from swin_transformer import final_model\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow.keras.backend as K\n",
    "import wandb\n",
    "from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "allowed_gpus = [0]\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "final_gpu_list = [gpus[x] for x in allowed_gpus]\n",
    "tf.config.set_visible_devices(final_gpu_list, 'GPU')\n",
    "for gpu in final_gpu_list:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "REPLICAS = strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = pd.read_csv('../../files/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>center_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>image_num</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>006388_0</td>\n",
       "      <td>11</td>\n",
       "      <td>006388</td>\n",
       "      <td>0</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>008e5c_0</td>\n",
       "      <td>11</td>\n",
       "      <td>008e5c</td>\n",
       "      <td>0</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00c058_0</td>\n",
       "      <td>11</td>\n",
       "      <td>00c058</td>\n",
       "      <td>0</td>\n",
       "      <td>LAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01adc5_0</td>\n",
       "      <td>11</td>\n",
       "      <td>01adc5</td>\n",
       "      <td>0</td>\n",
       "      <td>LAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>026c97_0</td>\n",
       "      <td>4</td>\n",
       "      <td>026c97</td>\n",
       "      <td>0</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id  center_id patient_id  image_num label\n",
       "0  006388_0         11     006388          0    CE\n",
       "1  008e5c_0         11     008e5c          0    CE\n",
       "2  00c058_0         11     00c058          0   LAA\n",
       "3  01adc5_0         11     01adc5          0   LAA\n",
       "4  026c97_0          4     026c97          0    CE"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file['fixed_paths'] = csv_file['image_id'].apply(lambda x: '../../files/resized_train/' + x + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>center_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>image_num</th>\n",
       "      <th>label</th>\n",
       "      <th>fixed_paths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>006388_0</td>\n",
       "      <td>11</td>\n",
       "      <td>006388</td>\n",
       "      <td>0</td>\n",
       "      <td>CE</td>\n",
       "      <td>../../files/resized_train/006388_0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>008e5c_0</td>\n",
       "      <td>11</td>\n",
       "      <td>008e5c</td>\n",
       "      <td>0</td>\n",
       "      <td>CE</td>\n",
       "      <td>../../files/resized_train/008e5c_0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00c058_0</td>\n",
       "      <td>11</td>\n",
       "      <td>00c058</td>\n",
       "      <td>0</td>\n",
       "      <td>LAA</td>\n",
       "      <td>../../files/resized_train/00c058_0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01adc5_0</td>\n",
       "      <td>11</td>\n",
       "      <td>01adc5</td>\n",
       "      <td>0</td>\n",
       "      <td>LAA</td>\n",
       "      <td>../../files/resized_train/01adc5_0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>026c97_0</td>\n",
       "      <td>4</td>\n",
       "      <td>026c97</td>\n",
       "      <td>0</td>\n",
       "      <td>CE</td>\n",
       "      <td>../../files/resized_train/026c97_0.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id  center_id patient_id  image_num label   \n",
       "0  006388_0         11     006388          0    CE  \\\n",
       "1  008e5c_0         11     008e5c          0    CE   \n",
       "2  00c058_0         11     00c058          0   LAA   \n",
       "3  01adc5_0         11     01adc5          0   LAA   \n",
       "4  026c97_0          4     026c97          0    CE   \n",
       "\n",
       "                              fixed_paths  \n",
       "0  ../../files/resized_train/006388_0.png  \n",
       "1  ../../files/resized_train/008e5c_0.png  \n",
       "2  ../../files/resized_train/00c058_0.png  \n",
       "3  ../../files/resized_train/01adc5_0.png  \n",
       "4  ../../files/resized_train/026c97_0.png  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in csv_file['fixed_paths'].values:\n",
    "    if os.path.exists(x) == False:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_datasets(csv_file, test_size = 0.01):\n",
    "    train, test = train_test_split(csv_file, test_size=test_size)\n",
    "    train, val = train_test_split(train, test_size=test_size)\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_imgs(img, label):\n",
    "    img = tf.io.read_file(img)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = img / 255\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(csv_file, repeat=True, shuffle=True, batch=True, batch_size=16):\n",
    "    imgs, labels = csv_file['fixed_paths'].values.tolist(), [1 if x == 'CE' else 0 for x in csv_file['label'].values.tolist()]\n",
    "    tensor = tf.data.Dataset.from_tensor_slices((imgs, labels))\n",
    "    tensor = tensor.cache()\n",
    "    if repeat:\n",
    "        tensor = tensor.repeat()\n",
    "    if shuffle:\n",
    "        tensor = tensor.shuffle(256 * REPLICAS)\n",
    "        opt = tf.data.Options()\n",
    "        opt.experimental_deterministic = False\n",
    "        tensor = tensor.with_options(opt)\n",
    "    tensor = tensor.map(read_imgs, num_parallel_calls=AUTO)\n",
    "    if batch:\n",
    "        tensor = tensor.batch(batch_size * REPLICAS)\n",
    "    tensor = tensor.prefetch(AUTO)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = split_datasets(csv_file, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_data(train)\n",
    "val_dataset = get_data(val)\n",
    "test_dataset = get_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (256, 256, 3)\n",
    "patch_size = (2,2)\n",
    "num_patch_x = input_shape[0] // patch_size[0]\n",
    "num_patch_y = input_shape[1] // patch_size[1]\n",
    "embed_dim = 64\n",
    "num_heads = 8\n",
    "window_size = 2\n",
    "dropout_rate = 0.0\n",
    "qkv_bias = True\n",
    "num_mlp = 256\n",
    "shift_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr = np.random.random((10, 256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model = final_model(input_shape, patch_size, embed_dim, num_heads, window_size, dropout_rate, qkv_bias, num_mlp, shift_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myashchks87\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/paperspace/Documents/mayo_strip_ai/notebooks/wandb/run-20230728_145901-bpj78u07</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yashchks87/mayo_strip_ai/runs/bpj78u07' target=\"_blank\">absurd-glade-15</a></strong> to <a href='https://wandb.ai/yashchks87/mayo_strip_ai' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yashchks87/mayo_strip_ai' target=\"_blank\">https://wandb.ai/yashchks87/mayo_strip_ai</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yashchks87/mayo_strip_ai/runs/bpj78u07' target=\"_blank\">https://wandb.ai/yashchks87/mayo_strip_ai/runs/bpj78u07</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "170/170 [==============================] - 72s 373ms/step - loss: 0.9248 - prec: 0.7495 - rec: 0.8320 - val_loss: 0.7181 - val_prec: 0.0000e+00 - val_rec: 0.0000e+00\n",
      "Epoch 2/100\n",
      "170/170 [==============================] - 61s 360ms/step - loss: 0.7983 - prec: 0.7451 - rec: 0.7691 - val_loss: 0.7603 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 3/100\n",
      "170/170 [==============================] - 61s 358ms/step - loss: 0.7020 - prec: 0.7245 - rec: 0.8839 - val_loss: 0.6199 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 4/100\n",
      "170/170 [==============================] - 61s 359ms/step - loss: 0.6186 - prec: 0.7192 - rec: 0.9776 - val_loss: 0.5789 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 5/100\n",
      "170/170 [==============================] - 61s 359ms/step - loss: 0.5973 - prec: 0.7432 - rec: 0.9821 - val_loss: 0.7722 - val_prec: 0.8889 - val_rec: 0.2963\n",
      "Epoch 6/100\n",
      "170/170 [==============================] - 61s 357ms/step - loss: 0.6149 - prec: 0.7377 - rec: 0.9841 - val_loss: 0.5981 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 7/100\n",
      "170/170 [==============================] - 60s 355ms/step - loss: 0.6148 - prec: 0.7208 - rec: 0.9694 - val_loss: 0.5749 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 8/100\n",
      "170/170 [==============================] - 60s 355ms/step - loss: 0.6145 - prec: 0.7261 - rec: 0.9980 - val_loss: 0.6574 - val_prec: 0.7429 - val_rec: 0.9630\n",
      "Epoch 9/100\n",
      "170/170 [==============================] - 60s 356ms/step - loss: 0.6845 - prec: 0.7309 - rec: 0.9310 - val_loss: 2.0644 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 10/100\n",
      "170/170 [==============================] - 61s 356ms/step - loss: 0.6810 - prec: 0.7248 - rec: 0.9332 - val_loss: 0.5602 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 11/100\n",
      "170/170 [==============================] - 61s 357ms/step - loss: 0.5487 - prec: 0.7470 - rec: 1.0000 - val_loss: 0.5779 - val_prec: 0.7429 - val_rec: 0.9630\n",
      "Epoch 12/100\n",
      "170/170 [==============================] - 61s 356ms/step - loss: 0.4108 - prec: 0.8259 - rec: 0.9529 - val_loss: 0.7472 - val_prec: 0.7429 - val_rec: 0.9630\n",
      "Epoch 13/100\n",
      "170/170 [==============================] - 61s 357ms/step - loss: 0.2840 - prec: 0.9015 - rec: 0.9585 - val_loss: 0.7802 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 14/100\n",
      "170/170 [==============================] - 61s 357ms/step - loss: 0.1161 - prec: 0.9530 - rec: 0.9898 - val_loss: 1.0251 - val_prec: 0.7353 - val_rec: 0.9259\n",
      "Epoch 15/100\n",
      "170/170 [==============================] - 61s 358ms/step - loss: 0.3090 - prec: 0.9006 - rec: 0.9398 - val_loss: 0.7385 - val_prec: 0.7037 - val_rec: 0.7037\n",
      "Epoch 16/100\n",
      "170/170 [==============================] - 61s 358ms/step - loss: 0.3409 - prec: 0.8643 - rec: 0.9745 - val_loss: 0.8262 - val_prec: 0.7241 - val_rec: 0.7778\n",
      "Epoch 17/100\n",
      "170/170 [==============================] - 61s 357ms/step - loss: 0.0661 - prec: 0.9744 - rec: 1.0000 - val_loss: 1.6737 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 18/100\n",
      "170/170 [==============================] - 61s 356ms/step - loss: 0.1251 - prec: 0.9587 - rec: 0.9780 - val_loss: 1.4832 - val_prec: 0.7931 - val_rec: 0.8519\n",
      "Epoch 19/100\n",
      "170/170 [==============================] - 60s 355ms/step - loss: 0.0443 - prec: 0.9858 - rec: 0.9959 - val_loss: 1.7292 - val_prec: 0.7188 - val_rec: 0.8519\n",
      "Epoch 20/100\n",
      "170/170 [==============================] - 60s 355ms/step - loss: 0.2809 - prec: 0.9412 - rec: 0.9619 - val_loss: 1.1764 - val_prec: 0.8333 - val_rec: 0.7407\n",
      "Epoch 21/100\n",
      "170/170 [==============================] - 61s 357ms/step - loss: 0.0579 - prec: 0.9841 - rec: 0.9880 - val_loss: 1.1479 - val_prec: 0.7647 - val_rec: 0.9630\n",
      "Epoch 22/100\n",
      "170/170 [==============================] - 61s 357ms/step - loss: 0.0320 - prec: 0.9842 - rec: 1.0000 - val_loss: 1.2797 - val_prec: 0.7586 - val_rec: 0.8148\n",
      "Epoch 23/100\n",
      "170/170 [==============================] - 60s 355ms/step - loss: 0.0232 - prec: 0.9920 - rec: 0.9980 - val_loss: 1.4764 - val_prec: 0.7667 - val_rec: 0.8519\n",
      "Epoch 24/100\n",
      "170/170 [==============================] - 60s 355ms/step - loss: 0.0176 - prec: 0.9917 - rec: 0.9979 - val_loss: 1.7335 - val_prec: 0.7667 - val_rec: 0.8519\n",
      "Epoch 25/100\n",
      "170/170 [==============================] - 60s 356ms/step - loss: 0.0156 - prec: 0.9921 - rec: 1.0000 - val_loss: 1.7093 - val_prec: 0.8214 - val_rec: 0.8519\n",
      "Epoch 26/100\n",
      "170/170 [==============================] - 61s 356ms/step - loss: 0.0080 - prec: 0.9980 - rec: 1.0000 - val_loss: 2.0727 - val_prec: 0.7500 - val_rec: 0.8889\n",
      "Epoch 27/100\n",
      "170/170 [==============================] - 61s 357ms/step - loss: 0.0156 - prec: 0.9919 - rec: 0.9980 - val_loss: 2.0009 - val_prec: 0.8000 - val_rec: 0.8889\n",
      "Epoch 28/100\n",
      "170/170 [==============================] - 61s 357ms/step - loss: 0.0680 - prec: 0.9783 - rec: 0.9822 - val_loss: 2.5495 - val_prec: 0.7273 - val_rec: 0.8889\n",
      "Epoch 29/100\n",
      "170/170 [==============================] - 60s 355ms/step - loss: 0.0254 - prec: 0.9920 - rec: 0.9980 - val_loss: 3.0899 - val_prec: 0.8000 - val_rec: 0.7407\n",
      "Epoch 30/100\n",
      "170/170 [==============================] - 60s 353ms/step - loss: 0.0617 - prec: 0.9838 - rec: 0.9858 - val_loss: 4.8309 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 31/100\n",
      "170/170 [==============================] - 60s 355ms/step - loss: 0.3325 - prec: 0.9282 - rec: 0.9409 - val_loss: 2.2017 - val_prec: 0.7353 - val_rec: 0.9259\n",
      "Epoch 32/100\n",
      "170/170 [==============================] - 60s 355ms/step - loss: 0.0546 - prec: 0.9780 - rec: 0.9980 - val_loss: 1.9262 - val_prec: 0.7647 - val_rec: 0.9630\n",
      "Epoch 33/100\n",
      "170/170 [==============================] - 60s 354ms/step - loss: 0.0198 - prec: 0.9940 - rec: 1.0000 - val_loss: 2.5503 - val_prec: 0.7333 - val_rec: 0.8148\n",
      "Epoch 34/100\n",
      "170/170 [==============================] - 60s 354ms/step - loss: 0.0977 - prec: 0.9816 - rec: 0.9756 - val_loss: 0.9177 - val_prec: 0.7429 - val_rec: 0.9630\n",
      "Epoch 35/100\n",
      "170/170 [==============================] - 60s 353ms/step - loss: 0.0724 - prec: 0.9743 - rec: 0.9940 - val_loss: 2.0953 - val_prec: 0.7273 - val_rec: 0.8889\n",
      "Epoch 36/100\n",
      "170/170 [==============================] - 60s 352ms/step - loss: 0.0178 - prec: 0.9940 - rec: 1.0000 - val_loss: 2.9392 - val_prec: 0.7586 - val_rec: 0.8148\n",
      "Epoch 37/100\n",
      "170/170 [==============================] - 60s 352ms/step - loss: 0.0138 - prec: 0.9920 - rec: 1.0000 - val_loss: 3.5030 - val_prec: 0.7600 - val_rec: 0.7037\n",
      "Epoch 38/100\n",
      "170/170 [==============================] - 60s 352ms/step - loss: 1.6456 - prec: 0.9122 - rec: 0.8994 - val_loss: 0.9636 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 39/100\n",
      "170/170 [==============================] - 60s 355ms/step - loss: 0.6416 - prec: 0.7255 - rec: 0.8988 - val_loss: 0.5312 - val_prec: 0.7429 - val_rec: 0.9630\n",
      "Epoch 40/100\n",
      "170/170 [==============================] - 60s 355ms/step - loss: 0.5262 - prec: 0.7654 - rec: 0.9720 - val_loss: 0.5511 - val_prec: 0.7429 - val_rec: 0.9630\n",
      "Epoch 41/100\n",
      "170/170 [==============================] - 60s 355ms/step - loss: 0.6929 - prec: 0.7901 - rec: 0.9256 - val_loss: 0.5530 - val_prec: 0.7429 - val_rec: 0.9630\n",
      "Epoch 42/100\n",
      "170/170 [==============================] - 60s 355ms/step - loss: 0.4289 - prec: 0.8084 - rec: 0.9862 - val_loss: 0.6980 - val_prec: 0.7429 - val_rec: 0.9630\n",
      "Epoch 43/100\n",
      "170/170 [==============================] - 60s 355ms/step - loss: 0.3657 - prec: 0.8319 - rec: 0.9856 - val_loss: 0.9482 - val_prec: 0.7647 - val_rec: 0.9630\n",
      "Epoch 44/100\n",
      "170/170 [==============================] - 60s 355ms/step - loss: 0.6292 - prec: 0.8339 - rec: 0.9248 - val_loss: 0.6597 - val_prec: 0.7429 - val_rec: 0.9630\n",
      "Epoch 45/100\n",
      "170/170 [==============================] - 60s 355ms/step - loss: 0.2667 - prec: 0.8814 - rec: 0.9940 - val_loss: 1.4683 - val_prec: 0.7500 - val_rec: 0.8889\n",
      "Epoch 46/100\n",
      "170/170 [==============================] - 60s 354ms/step - loss: 0.0892 - prec: 0.9583 - rec: 0.9918 - val_loss: 2.3978 - val_prec: 0.7742 - val_rec: 0.8889\n",
      "Epoch 47/100\n",
      "170/170 [==============================] - 60s 354ms/step - loss: 0.0333 - prec: 0.9839 - rec: 0.9980 - val_loss: 2.6501 - val_prec: 0.7586 - val_rec: 0.8148\n",
      "Epoch 48/100\n",
      "170/170 [==============================] - 60s 354ms/step - loss: 0.0276 - prec: 0.9881 - rec: 1.0000 - val_loss: 2.5481 - val_prec: 0.7931 - val_rec: 0.8519\n",
      "Epoch 49/100\n",
      "170/170 [==============================] - 60s 354ms/step - loss: 0.0185 - prec: 0.9941 - rec: 1.0000 - val_loss: 3.1462 - val_prec: 0.7778 - val_rec: 0.7778\n",
      "Epoch 50/100\n",
      "170/170 [==============================] - 60s 354ms/step - loss: 0.0128 - prec: 0.9939 - rec: 1.0000 - val_loss: 3.8702 - val_prec: 0.7778 - val_rec: 0.7778\n",
      "Epoch 51/100\n",
      "170/170 [==============================] - 60s 354ms/step - loss: 0.0165 - prec: 0.9939 - rec: 0.9980 - val_loss: 4.0220 - val_prec: 0.7826 - val_rec: 0.6667\n",
      "Epoch 52/100\n",
      "170/170 [==============================] - 60s 356ms/step - loss: 0.0262 - prec: 0.9902 - rec: 1.0000 - val_loss: 3.3434 - val_prec: 0.8000 - val_rec: 0.8889\n",
      "Epoch 53/100\n",
      "170/170 [==============================] - 60s 354ms/step - loss: 0.0158 - prec: 0.9939 - rec: 1.0000 - val_loss: 4.5222 - val_prec: 0.7500 - val_rec: 0.7778\n",
      "Epoch 54/100\n",
      "170/170 [==============================] - 60s 354ms/step - loss: 0.0066 - prec: 0.9981 - rec: 1.0000 - val_loss: 4.9972 - val_prec: 0.7500 - val_rec: 0.7778\n",
      "Epoch 55/100\n",
      "170/170 [==============================] - 60s 355ms/step - loss: 0.0072 - prec: 0.9959 - rec: 1.0000 - val_loss: 5.0170 - val_prec: 0.7778 - val_rec: 0.7778\n",
      "Epoch 56/100\n",
      "170/170 [==============================] - 60s 354ms/step - loss: 0.0034 - prec: 0.9980 - rec: 1.0000 - val_loss: 5.6046 - val_prec: 0.8000 - val_rec: 0.7407\n",
      "Epoch 57/100\n",
      "170/170 [==============================] - 60s 353ms/step - loss: 0.0046 - prec: 0.9980 - rec: 1.0000 - val_loss: 7.9311 - val_prec: 0.7368 - val_rec: 0.5185\n",
      "Epoch 58/100\n",
      "170/170 [==============================] - 60s 354ms/step - loss: 0.3011 - prec: 0.9332 - rec: 0.9466 - val_loss: 1.2366 - val_prec: 0.7576 - val_rec: 0.9259\n",
      "Epoch 59/100\n",
      "170/170 [==============================] - 60s 355ms/step - loss: 0.0547 - prec: 0.9779 - rec: 0.9939 - val_loss: 2.2413 - val_prec: 0.7500 - val_rec: 0.7778\n",
      "Epoch 60/100\n",
      "170/170 [==============================] - 60s 355ms/step - loss: 0.1020 - prec: 0.9762 - rec: 0.9781 - val_loss: 1.5084 - val_prec: 0.7576 - val_rec: 0.9259\n",
      "Epoch 61/100\n",
      "170/170 [==============================] - 60s 354ms/step - loss: 0.0371 - prec: 0.9879 - rec: 0.9879 - val_loss: 2.9190 - val_prec: 0.7778 - val_rec: 0.7778\n",
      "Epoch 62/100\n",
      "170/170 [==============================] - 60s 355ms/step - loss: 0.0098 - prec: 0.9980 - rec: 1.0000 - val_loss: 3.0007 - val_prec: 0.7857 - val_rec: 0.8148\n",
      "Epoch 63/100\n",
      "170/170 [==============================] - 60s 354ms/step - loss: 0.0130 - prec: 0.9900 - rec: 1.0000 - val_loss: 3.4167 - val_prec: 0.7500 - val_rec: 0.7778\n",
      "Epoch 64/100\n",
      "170/170 [==============================] - 60s 356ms/step - loss: 0.0059 - prec: 0.9980 - rec: 1.0000 - val_loss: 3.8775 - val_prec: 0.7586 - val_rec: 0.8148\n",
      "Epoch 65/100\n",
      "170/170 [==============================] - 60s 353ms/step - loss: 0.0047 - prec: 0.9979 - rec: 1.0000 - val_loss: 4.1095 - val_prec: 0.7857 - val_rec: 0.8148\n",
      "Epoch 66/100\n",
      "170/170 [==============================] - 60s 353ms/step - loss: 0.0041 - prec: 1.0000 - rec: 1.0000 - val_loss: 4.7100 - val_prec: 0.7586 - val_rec: 0.8148\n",
      "Epoch 67/100\n",
      "170/170 [==============================] - 60s 353ms/step - loss: 0.0034 - prec: 0.9980 - rec: 1.0000 - val_loss: 4.9691 - val_prec: 0.7586 - val_rec: 0.8148\n",
      "Epoch 68/100\n",
      "170/170 [==============================] - 60s 353ms/step - loss: 0.0027 - prec: 1.0000 - rec: 1.0000 - val_loss: 4.9561 - val_prec: 0.7586 - val_rec: 0.8148\n",
      "Epoch 69/100\n",
      "170/170 [==============================] - 60s 353ms/step - loss: 0.0025 - prec: 0.9980 - rec: 1.0000 - val_loss: 5.5755 - val_prec: 0.7857 - val_rec: 0.8148\n",
      "Epoch 70/100\n",
      "170/170 [==============================] - 60s 353ms/step - loss: 0.0017 - prec: 1.0000 - rec: 1.0000 - val_loss: 5.7001 - val_prec: 0.7778 - val_rec: 0.7778\n",
      "Epoch 71/100\n",
      "170/170 [==============================] - 60s 353ms/step - loss: 0.0010 - prec: 1.0000 - rec: 1.0000 - val_loss: 6.5153 - val_prec: 0.7857 - val_rec: 0.8148\n",
      "Epoch 72/100\n",
      "170/170 [==============================] - 60s 354ms/step - loss: 0.0021 - prec: 1.0000 - rec: 1.0000 - val_loss: 7.0874 - val_prec: 0.7857 - val_rec: 0.8148\n",
      "Epoch 73/100\n",
      "170/170 [==============================] - 60s 353ms/step - loss: 4.7219e-04 - prec: 1.0000 - rec: 1.0000 - val_loss: 7.0876 - val_prec: 0.7857 - val_rec: 0.8148\n",
      "Epoch 74/100\n",
      "170/170 [==============================] - 60s 354ms/step - loss: 0.0018 - prec: 1.0000 - rec: 1.0000 - val_loss: 7.1570 - val_prec: 0.7500 - val_rec: 0.7778\n",
      "Epoch 75/100\n",
      "170/170 [==============================] - 60s 354ms/step - loss: 0.0049 - prec: 0.9980 - rec: 0.9980 - val_loss: 5.4606 - val_prec: 0.7879 - val_rec: 0.9630\n",
      "Epoch 76/100\n",
      "170/170 [==============================] - 61s 358ms/step - loss: 2.3535 - prec: 0.7404 - rec: 0.8936 - val_loss: 0.5550 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 77/100\n",
      "170/170 [==============================] - 61s 359ms/step - loss: 0.2839 - prec: 0.8759 - rec: 0.9796 - val_loss: 1.8957 - val_prec: 0.8000 - val_rec: 0.5926\n",
      "Epoch 78/100\n",
      "170/170 [==============================] - 61s 357ms/step - loss: 0.0866 - prec: 0.9668 - rec: 0.9940 - val_loss: 1.6441 - val_prec: 0.7692 - val_rec: 0.7407\n",
      "Epoch 79/100\n",
      "170/170 [==============================] - 61s 358ms/step - loss: 0.0611 - prec: 0.9767 - rec: 0.9862 - val_loss: 1.7832 - val_prec: 0.8636 - val_rec: 0.7037\n",
      "Epoch 80/100\n",
      "170/170 [==============================] - 60s 355ms/step - loss: 0.0349 - prec: 0.9899 - rec: 0.9939 - val_loss: 1.5234 - val_prec: 0.8077 - val_rec: 0.7778\n",
      "Epoch 81/100\n",
      "170/170 [==============================] - 60s 356ms/step - loss: 0.0499 - prec: 0.9840 - rec: 0.9899 - val_loss: 2.0431 - val_prec: 0.8462 - val_rec: 0.8148\n",
      "Epoch 82/100\n",
      "170/170 [==============================] - 60s 355ms/step - loss: 0.0492 - prec: 0.9857 - rec: 0.9938 - val_loss: 1.6055 - val_prec: 0.8519 - val_rec: 0.8519\n",
      "Epoch 83/100\n",
      "170/170 [==============================] - 60s 354ms/step - loss: 0.0162 - prec: 0.9921 - rec: 1.0000 - val_loss: 1.8064 - val_prec: 0.7917 - val_rec: 0.7037\n",
      "Epoch 84/100\n",
      "170/170 [==============================] - 60s 354ms/step - loss: 0.0084 - prec: 0.9959 - rec: 1.0000 - val_loss: 2.4228 - val_prec: 0.8500 - val_rec: 0.6296\n",
      "Epoch 85/100\n",
      "170/170 [==============================] - 60s 353ms/step - loss: 0.0055 - prec: 0.9980 - rec: 1.0000 - val_loss: 2.1682 - val_prec: 0.8261 - val_rec: 0.7037\n",
      "Epoch 86/100\n",
      "170/170 [==============================] - 60s 353ms/step - loss: 0.0069 - prec: 0.9959 - rec: 1.0000 - val_loss: 1.9347 - val_prec: 0.8636 - val_rec: 0.7037\n",
      "Epoch 87/100\n",
      "170/170 [==============================] - 60s 353ms/step - loss: 0.0051 - prec: 0.9961 - rec: 1.0000 - val_loss: 2.6634 - val_prec: 0.8500 - val_rec: 0.6296\n",
      "Epoch 88/100\n",
      "170/170 [==============================] - 60s 354ms/step - loss: 0.0059 - prec: 0.9979 - rec: 0.9979 - val_loss: 3.3554 - val_prec: 0.7826 - val_rec: 0.6667\n",
      "Epoch 89/100\n",
      "170/170 [==============================] - 60s 354ms/step - loss: 0.0086 - prec: 0.9960 - rec: 0.9980 - val_loss: 2.7903 - val_prec: 0.8077 - val_rec: 0.7778\n",
      "Epoch 90/100\n",
      "170/170 [==============================] - 61s 356ms/step - loss: 0.0036 - prec: 0.9961 - rec: 1.0000 - val_loss: 2.8211 - val_prec: 0.8333 - val_rec: 0.7407\n",
      "Epoch 91/100\n",
      "170/170 [==============================] - 60s 355ms/step - loss: 0.0077 - prec: 0.9959 - rec: 1.0000 - val_loss: 3.7235 - val_prec: 0.7692 - val_rec: 0.7407\n",
      "Epoch 92/100\n",
      "170/170 [==============================] - 60s 356ms/step - loss: 7.5197e-04 - prec: 1.0000 - rec: 1.0000 - val_loss: 3.3482 - val_prec: 0.8148 - val_rec: 0.8148\n",
      "Epoch 93/100\n",
      "170/170 [==============================] - 60s 354ms/step - loss: 0.0013 - prec: 1.0000 - rec: 1.0000 - val_loss: 3.6016 - val_prec: 0.8077 - val_rec: 0.7778\n",
      "Epoch 94/100\n",
      "170/170 [==============================] - 60s 354ms/step - loss: 2.7511e-04 - prec: 1.0000 - rec: 1.0000 - val_loss: 3.6455 - val_prec: 0.8077 - val_rec: 0.7778\n",
      "Epoch 95/100\n",
      "170/170 [==============================] - 60s 354ms/step - loss: 9.0119e-04 - prec: 1.0000 - rec: 1.0000 - val_loss: 3.9858 - val_prec: 0.8000 - val_rec: 0.7407\n",
      "Epoch 96/100\n",
      "170/170 [==============================] - 60s 355ms/step - loss: 4.3200e-04 - prec: 1.0000 - rec: 1.0000 - val_loss: 3.8645 - val_prec: 0.8000 - val_rec: 0.7407\n",
      "Epoch 97/100\n",
      "170/170 [==============================] - 60s 354ms/step - loss: 1.1795e-04 - prec: 1.0000 - rec: 1.0000 - val_loss: 3.6532 - val_prec: 0.8000 - val_rec: 0.7407\n",
      "Epoch 98/100\n",
      "170/170 [==============================] - 60s 356ms/step - loss: 4.0583e-04 - prec: 1.0000 - rec: 1.0000 - val_loss: 3.8974 - val_prec: 0.8000 - val_rec: 0.7407\n",
      "Epoch 99/100\n",
      "170/170 [==============================] - 60s 355ms/step - loss: 8.8759e-05 - prec: 1.0000 - rec: 1.0000 - val_loss: 3.7812 - val_prec: 0.8000 - val_rec: 0.7407\n",
      "Epoch 100/100\n",
      "170/170 [==============================] - 60s 356ms/step - loss: 1.3360e-04 - prec: 1.0000 - rec: 1.0000 - val_loss: 3.7449 - val_prec: 0.7692 - val_rec: 0.7407\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "# log_dir = f\"{os.environ['tb_path']}segmentation/res50_baseline_bs_128_is_32/\"\n",
    "# if os.path.exists(log_dir) == False:\n",
    "#     os.makedirs(log_dir)\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir)\n",
    "weights_path = f'../../weights_mayo_strip_ai/swin_version_1/'\n",
    "weights_save = CallbackForSavingModelWeights(weights_path)\n",
    "batch_size = 4\n",
    "train_dataset = get_data(train, batch_size=batch_size)\n",
    "val_dataset = get_data(val, shuffle=False, repeat=False, batch_size=batch_size)\n",
    "# model_config_file\n",
    "input_shape = (256, 256, 3)\n",
    "patch_size = (2, 2)\n",
    "num_patch_x = input_shape[0] // patch_size[0]\n",
    "num_patch_y = input_shape[1] // patch_size[1]\n",
    "embed_dim = 128\n",
    "num_heads = 16\n",
    "window_size = 2\n",
    "dropout_rate = 0.0\n",
    "qkv_bias = False\n",
    "num_mlp = 1024\n",
    "shift_size = 1\n",
    "with strategy.scope():\n",
    "    model = final_model(input_shape, patch_size, embed_dim, num_heads, window_size, dropout_rate, qkv_bias, num_mlp, shift_size)\n",
    "wandb.init(\n",
    "    project = 'mayo_strip_ai',\n",
    "    # Please add number of epochs\n",
    "    config = {\n",
    "        'input_shape' : input_shape,\n",
    "        'patch_size' : patch_size,\n",
    "        'num_patch_x' : num_patch_x,\n",
    "        'num_patch_y' : num_patch_y, \n",
    "        'embed_dim' : embed_dim,\n",
    "        'num_heads' : num_heads,\n",
    "        'window_size' : window_size,\n",
    "        'dropout_rate' : dropout_rate,\n",
    "        'qkv_bias' : qkv_bias,\n",
    "        'num_mlp' : num_mlp,\n",
    "        'shift_size' : shift_size,\n",
    "        'optim' : model.optimizer,\n",
    "        'batch_size' : batch_size,\n",
    "    }\n",
    ")\n",
    "# model traning loop\n",
    "with strategy.scope():\n",
    "    model_hist = model.fit(\n",
    "        train_dataset,\n",
    "        steps_per_epoch = len(train) // (batch_size * REPLICAS),\n",
    "        epochs = 100,\n",
    "        verbose = 1,\n",
    "        validation_data = val_dataset,\n",
    "        # callbacks = [tensorboard_callback]\n",
    "        callbacks = [\n",
    "            WandbMetricsLogger()\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:bpj78u07) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▆▆▆▅▃▄▂▁▁▁▂▄▂▁▆▆▆▂▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/prec</td><td>▂▁▁▁▂▅▅▇███▇▆██▁▃▄▇████▇██████▅▇████████</td></tr><tr><td>epoch/rec</td><td>▁▃▇██▆▇▇▇██▇▆▇█▄▅▅██████▇█████▇▇████████</td></tr><tr><td>epoch/val_loss</td><td>▁▁▁▁▁▁▁▂▂▂▃▃▃▁▄▁▁▁▃▄▅▆▆▃▄▅▆▆██▂▂▂▃▃▃▄▄▄▄</td></tr><tr><td>epoch/val_prec</td><td>▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████▇▇</td></tr><tr><td>epoch/val_rec</td><td>▁█████▆▇█▇▇▇▇█▇███▇▆▆▆▆▆▆▇▇▇▇▆▅▆▇▅▅▆▇▆▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.00013</td></tr><tr><td>epoch/prec</td><td>1.0</td></tr><tr><td>epoch/rec</td><td>1.0</td></tr><tr><td>epoch/val_loss</td><td>3.74486</td></tr><tr><td>epoch/val_prec</td><td>0.76923</td></tr><tr><td>epoch/val_rec</td><td>0.74074</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">absurd-glade-15</strong> at: <a href='https://wandb.ai/yashchks87/mayo_strip_ai/runs/bpj78u07' target=\"_blank\">https://wandb.ai/yashchks87/mayo_strip_ai/runs/bpj78u07</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230728_145901-bpj78u07/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:bpj78u07). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/paperspace/Documents/mayo_strip_ai/notebooks/wandb/run-20230728_163952-juqyq7ou</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yashchks87/mayo_strip_ai/runs/juqyq7ou' target=\"_blank\">fast-sun-16</a></strong> to <a href='https://wandb.ai/yashchks87/mayo_strip_ai' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yashchks87/mayo_strip_ai' target=\"_blank\">https://wandb.ai/yashchks87/mayo_strip_ai</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yashchks87/mayo_strip_ai/runs/juqyq7ou' target=\"_blank\">https://wandb.ai/yashchks87/mayo_strip_ai/runs/juqyq7ou</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "170/170 [==============================] - 36s 164ms/step - loss: 0.7550 - prec: 0.7259 - rec: 0.8522 - val_loss: 0.5675 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 2/100\n",
      "170/170 [==============================] - 25s 150ms/step - loss: 0.6481 - prec: 0.7288 - rec: 0.9678 - val_loss: 0.5898 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 3/100\n",
      "170/170 [==============================] - 25s 149ms/step - loss: 0.6313 - prec: 0.7317 - rec: 0.9343 - val_loss: 0.5668 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 4/100\n",
      "170/170 [==============================] - 25s 149ms/step - loss: 0.6213 - prec: 0.7192 - rec: 0.9878 - val_loss: 0.5717 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 5/100\n",
      "170/170 [==============================] - 25s 149ms/step - loss: 0.5960 - prec: 0.7353 - rec: 1.0000 - val_loss: 0.5760 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 6/100\n",
      "170/170 [==============================] - 25s 149ms/step - loss: 0.6036 - prec: 0.7339 - rec: 0.9639 - val_loss: 0.6375 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 7/100\n",
      "170/170 [==============================] - 25s 149ms/step - loss: 0.6016 - prec: 0.7238 - rec: 0.9571 - val_loss: 0.6200 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 8/100\n",
      "170/170 [==============================] - 25s 149ms/step - loss: 0.5964 - prec: 0.7370 - rec: 0.9718 - val_loss: 0.6162 - val_prec: 0.7353 - val_rec: 0.9259\n",
      "Epoch 9/100\n",
      "170/170 [==============================] - 25s 147ms/step - loss: 0.5089 - prec: 0.7815 - rec: 0.9440 - val_loss: 0.6877 - val_prec: 0.7419 - val_rec: 0.8519\n",
      "Epoch 10/100\n",
      "170/170 [==============================] - 25s 147ms/step - loss: 0.3299 - prec: 0.8736 - rec: 0.9675 - val_loss: 0.6595 - val_prec: 0.7619 - val_rec: 0.5926\n",
      "Epoch 11/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 0.1199 - prec: 0.9497 - rec: 0.9879 - val_loss: 1.0898 - val_prec: 0.7667 - val_rec: 0.8519\n",
      "Epoch 12/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 0.0574 - prec: 0.9726 - rec: 0.9960 - val_loss: 1.2709 - val_prec: 0.7419 - val_rec: 0.8519\n",
      "Epoch 13/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 0.0376 - prec: 0.9821 - rec: 1.0000 - val_loss: 1.1831 - val_prec: 0.8000 - val_rec: 0.7407\n",
      "Epoch 14/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 1.3662 - prec: 0.8788 - rec: 0.9104 - val_loss: 0.7228 - val_prec: 0.7586 - val_rec: 0.8148\n",
      "Epoch 15/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 0.0775 - prec: 0.9683 - rec: 0.9980 - val_loss: 0.9714 - val_prec: 0.8095 - val_rec: 0.6296\n",
      "Epoch 16/100\n",
      "170/170 [==============================] - 25s 147ms/step - loss: 0.0441 - prec: 0.9803 - rec: 1.0000 - val_loss: 0.9129 - val_prec: 0.7778 - val_rec: 0.7778\n",
      "Epoch 17/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 0.0479 - prec: 0.9803 - rec: 1.0000 - val_loss: 1.0243 - val_prec: 0.8696 - val_rec: 0.7407\n",
      "Epoch 18/100\n",
      "170/170 [==============================] - 25s 147ms/step - loss: 0.0393 - prec: 0.9861 - rec: 0.9980 - val_loss: 1.1589 - val_prec: 0.7857 - val_rec: 0.8148\n",
      "Epoch 19/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 0.0268 - prec: 0.9860 - rec: 1.0000 - val_loss: 1.1292 - val_prec: 0.7667 - val_rec: 0.8519\n",
      "Epoch 20/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 0.0168 - prec: 0.9940 - rec: 1.0000 - val_loss: 1.2880 - val_prec: 0.7931 - val_rec: 0.8519\n",
      "Epoch 21/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 0.0221 - prec: 0.9899 - rec: 1.0000 - val_loss: 1.3554 - val_prec: 0.7742 - val_rec: 0.8889\n",
      "Epoch 22/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 0.0368 - prec: 0.9882 - rec: 0.9980 - val_loss: 1.3226 - val_prec: 0.7419 - val_rec: 0.8519\n",
      "Epoch 23/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 0.0166 - prec: 0.9940 - rec: 1.0000 - val_loss: 2.1405 - val_prec: 0.7931 - val_rec: 0.8519\n",
      "Epoch 24/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 0.0196 - prec: 0.9919 - rec: 1.0000 - val_loss: 1.7468 - val_prec: 0.8462 - val_rec: 0.8148\n",
      "Epoch 25/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 0.0622 - prec: 0.9799 - rec: 0.9878 - val_loss: 2.1904 - val_prec: 0.8462 - val_rec: 0.4074\n",
      "Epoch 26/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 0.0410 - prec: 0.9824 - rec: 0.9960 - val_loss: 2.1721 - val_prec: 0.7692 - val_rec: 0.7407\n",
      "Epoch 27/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 0.0099 - prec: 0.9940 - rec: 1.0000 - val_loss: 1.9826 - val_prec: 0.7586 - val_rec: 0.8148\n",
      "Epoch 28/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 0.0045 - prec: 0.9980 - rec: 1.0000 - val_loss: 1.9946 - val_prec: 0.8000 - val_rec: 0.7407\n",
      "Epoch 29/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 0.0043 - prec: 0.9980 - rec: 1.0000 - val_loss: 2.0257 - val_prec: 0.7857 - val_rec: 0.8148\n",
      "Epoch 30/100\n",
      "170/170 [==============================] - 25s 145ms/step - loss: 0.0134 - prec: 0.9940 - rec: 1.0000 - val_loss: 2.0328 - val_prec: 0.8462 - val_rec: 0.8148\n",
      "Epoch 31/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 0.0098 - prec: 0.9940 - rec: 1.0000 - val_loss: 2.4803 - val_prec: 0.8696 - val_rec: 0.7407\n",
      "Epoch 32/100\n",
      "170/170 [==============================] - 25s 145ms/step - loss: 0.0049 - prec: 0.9980 - rec: 1.0000 - val_loss: 2.2969 - val_prec: 0.8000 - val_rec: 0.7407\n",
      "Epoch 33/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 0.0622 - prec: 0.9838 - rec: 0.9878 - val_loss: 1.6326 - val_prec: 0.9130 - val_rec: 0.7778\n",
      "Epoch 34/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 0.1694 - prec: 0.9527 - rec: 0.9718 - val_loss: 1.2352 - val_prec: 0.7586 - val_rec: 0.8148\n",
      "Epoch 35/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 0.2143 - prec: 0.9582 - rec: 0.9620 - val_loss: 2.3003 - val_prec: 0.7407 - val_rec: 0.7407\n",
      "Epoch 36/100\n",
      "170/170 [==============================] - 25s 145ms/step - loss: 0.0455 - prec: 0.9800 - rec: 0.9980 - val_loss: 2.6759 - val_prec: 0.7692 - val_rec: 0.7407\n",
      "Epoch 37/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 0.0228 - prec: 0.9900 - rec: 0.9980 - val_loss: 2.2766 - val_prec: 0.7778 - val_rec: 0.7778\n",
      "Epoch 38/100\n",
      "170/170 [==============================] - 25s 145ms/step - loss: 0.0036 - prec: 1.0000 - rec: 1.0000 - val_loss: 2.6796 - val_prec: 0.7778 - val_rec: 0.7778\n",
      "Epoch 39/100\n",
      "170/170 [==============================] - 25s 145ms/step - loss: 0.0103 - prec: 0.9941 - rec: 1.0000 - val_loss: 2.8964 - val_prec: 0.8077 - val_rec: 0.7778\n",
      "Epoch 40/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 0.0031 - prec: 0.9980 - rec: 1.0000 - val_loss: 3.0038 - val_prec: 0.7857 - val_rec: 0.8148\n",
      "Epoch 41/100\n",
      "170/170 [==============================] - 25s 147ms/step - loss: 0.0089 - prec: 0.9939 - rec: 1.0000 - val_loss: 3.2137 - val_prec: 0.8077 - val_rec: 0.7778\n",
      "Epoch 42/100\n",
      "170/170 [==============================] - 25s 147ms/step - loss: 0.0039 - prec: 0.9980 - rec: 1.0000 - val_loss: 3.3413 - val_prec: 0.8077 - val_rec: 0.7778\n",
      "Epoch 43/100\n",
      "170/170 [==============================] - 25s 148ms/step - loss: 0.0021 - prec: 1.0000 - rec: 1.0000 - val_loss: 3.4031 - val_prec: 0.7857 - val_rec: 0.8148\n",
      "Epoch 44/100\n",
      "170/170 [==============================] - 25s 148ms/step - loss: 0.0055 - prec: 0.9980 - rec: 1.0000 - val_loss: 3.7716 - val_prec: 0.8077 - val_rec: 0.7778\n",
      "Epoch 45/100\n",
      "170/170 [==============================] - 25s 147ms/step - loss: 0.0040 - prec: 0.9980 - rec: 1.0000 - val_loss: 2.8558 - val_prec: 0.8462 - val_rec: 0.8148\n",
      "Epoch 46/100\n",
      "170/170 [==============================] - 25s 148ms/step - loss: 0.0038 - prec: 1.0000 - rec: 1.0000 - val_loss: 3.9029 - val_prec: 0.8077 - val_rec: 0.7778\n",
      "Epoch 47/100\n",
      "170/170 [==============================] - 25s 148ms/step - loss: 0.0020 - prec: 1.0000 - rec: 1.0000 - val_loss: 3.7506 - val_prec: 0.7857 - val_rec: 0.8148\n",
      "Epoch 48/100\n",
      "170/170 [==============================] - 25s 147ms/step - loss: 0.0018 - prec: 1.0000 - rec: 1.0000 - val_loss: 3.9727 - val_prec: 0.8077 - val_rec: 0.7778\n",
      "Epoch 49/100\n",
      "170/170 [==============================] - 25s 150ms/step - loss: 0.0994 - prec: 0.9859 - rec: 0.9840 - val_loss: 4.4393 - val_prec: 0.7429 - val_rec: 0.9630\n",
      "Epoch 50/100\n",
      "170/170 [==============================] - 25s 149ms/step - loss: 0.1914 - prec: 0.9584 - rec: 0.9699 - val_loss: 2.5407 - val_prec: 0.7308 - val_rec: 0.7037\n",
      "Epoch 51/100\n",
      "170/170 [==============================] - 25s 149ms/step - loss: 0.0600 - prec: 0.9799 - rec: 0.9858 - val_loss: 1.7649 - val_prec: 0.7727 - val_rec: 0.6296\n",
      "Epoch 52/100\n",
      "170/170 [==============================] - 25s 149ms/step - loss: 0.0464 - prec: 0.9805 - rec: 0.9980 - val_loss: 2.1027 - val_prec: 0.7500 - val_rec: 0.7778\n",
      "Epoch 53/100\n",
      "170/170 [==============================] - 25s 149ms/step - loss: 0.0202 - prec: 0.9901 - rec: 1.0000 - val_loss: 2.4342 - val_prec: 0.7143 - val_rec: 0.7407\n",
      "Epoch 54/100\n",
      "170/170 [==============================] - 26s 150ms/step - loss: 0.0136 - prec: 0.9919 - rec: 1.0000 - val_loss: 3.2241 - val_prec: 0.7308 - val_rec: 0.7037\n",
      "Epoch 55/100\n",
      "170/170 [==============================] - 26s 151ms/step - loss: 0.0115 - prec: 0.9919 - rec: 1.0000 - val_loss: 3.5896 - val_prec: 0.7778 - val_rec: 0.7778\n",
      "Epoch 56/100\n",
      "170/170 [==============================] - 25s 149ms/step - loss: 0.0064 - prec: 0.9960 - rec: 1.0000 - val_loss: 3.9123 - val_prec: 0.7778 - val_rec: 0.7778\n",
      "Epoch 57/100\n",
      "170/170 [==============================] - 25s 147ms/step - loss: 0.0031 - prec: 1.0000 - rec: 1.0000 - val_loss: 3.6193 - val_prec: 0.8077 - val_rec: 0.7778\n",
      "Epoch 58/100\n",
      "170/170 [==============================] - 25s 147ms/step - loss: 0.0048 - prec: 0.9980 - rec: 1.0000 - val_loss: 4.6915 - val_prec: 0.7778 - val_rec: 0.7778\n",
      "Epoch 59/100\n",
      "170/170 [==============================] - 25s 148ms/step - loss: 0.0018 - prec: 1.0000 - rec: 1.0000 - val_loss: 4.9082 - val_prec: 0.7778 - val_rec: 0.7778\n",
      "Epoch 60/100\n",
      "170/170 [==============================] - 25s 150ms/step - loss: 0.0016 - prec: 1.0000 - rec: 1.0000 - val_loss: 3.6616 - val_prec: 0.8077 - val_rec: 0.7778\n",
      "Epoch 61/100\n",
      "170/170 [==============================] - 25s 149ms/step - loss: 0.0019 - prec: 1.0000 - rec: 1.0000 - val_loss: 5.0743 - val_prec: 0.7500 - val_rec: 0.7778\n",
      "Epoch 62/100\n",
      "170/170 [==============================] - 25s 149ms/step - loss: 0.0042 - prec: 0.9980 - rec: 1.0000 - val_loss: 4.7480 - val_prec: 0.8077 - val_rec: 0.7778\n",
      "Epoch 63/100\n",
      "170/170 [==============================] - 25s 149ms/step - loss: 4.0958e-04 - prec: 1.0000 - rec: 1.0000 - val_loss: 4.8063 - val_prec: 0.8148 - val_rec: 0.8148\n",
      "Epoch 64/100\n",
      "170/170 [==============================] - 25s 149ms/step - loss: 0.0010 - prec: 1.0000 - rec: 1.0000 - val_loss: 4.8392 - val_prec: 0.8077 - val_rec: 0.7778\n",
      "Epoch 65/100\n",
      "170/170 [==============================] - 25s 148ms/step - loss: 3.8315e-04 - prec: 1.0000 - rec: 1.0000 - val_loss: 4.8647 - val_prec: 0.7857 - val_rec: 0.8148\n",
      "Epoch 66/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 1.8328e-04 - prec: 1.0000 - rec: 1.0000 - val_loss: 4.7043 - val_prec: 0.7857 - val_rec: 0.8148\n",
      "Epoch 67/100\n",
      "170/170 [==============================] - 25s 147ms/step - loss: 6.5215e-04 - prec: 1.0000 - rec: 1.0000 - val_loss: 5.2756 - val_prec: 0.8148 - val_rec: 0.8148\n",
      "Epoch 68/100\n",
      "170/170 [==============================] - 25s 147ms/step - loss: 3.4249e-04 - prec: 1.0000 - rec: 1.0000 - val_loss: 5.0745 - val_prec: 0.7857 - val_rec: 0.8148\n",
      "Epoch 69/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 3.6334e-04 - prec: 1.0000 - rec: 1.0000 - val_loss: 5.4126 - val_prec: 0.8077 - val_rec: 0.7778\n",
      "Epoch 70/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 6.1931e-04 - prec: 1.0000 - rec: 1.0000 - val_loss: 6.7796 - val_prec: 0.7586 - val_rec: 0.8148\n",
      "Epoch 71/100\n",
      "170/170 [==============================] - 25s 145ms/step - loss: 0.8002 - prec: 0.8234 - rec: 0.9140 - val_loss: 0.5886 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 72/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 0.4739 - prec: 0.7922 - rec: 0.9548 - val_loss: 0.7355 - val_prec: 0.7097 - val_rec: 0.8148\n",
      "Epoch 73/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 0.2284 - prec: 0.9196 - rec: 0.9630 - val_loss: 1.2798 - val_prec: 0.7500 - val_rec: 0.7778\n",
      "Epoch 74/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 0.0943 - prec: 0.9575 - rec: 0.9920 - val_loss: 2.3806 - val_prec: 0.8000 - val_rec: 0.7407\n",
      "Epoch 75/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 0.0438 - prec: 0.9821 - rec: 1.0000 - val_loss: 2.7179 - val_prec: 0.7500 - val_rec: 0.7778\n",
      "Epoch 76/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 0.0354 - prec: 0.9843 - rec: 1.0000 - val_loss: 2.8093 - val_prec: 0.8000 - val_rec: 0.7407\n",
      "Epoch 77/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 0.0185 - prec: 0.9940 - rec: 0.9980 - val_loss: 3.4781 - val_prec: 0.8077 - val_rec: 0.7778\n",
      "Epoch 78/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 0.0158 - prec: 0.9899 - rec: 0.9980 - val_loss: 3.9234 - val_prec: 0.7778 - val_rec: 0.7778\n",
      "Epoch 79/100\n",
      "170/170 [==============================] - 25s 147ms/step - loss: 0.0102 - prec: 0.9960 - rec: 1.0000 - val_loss: 4.3037 - val_prec: 0.7500 - val_rec: 0.7778\n",
      "Epoch 80/100\n",
      "170/170 [==============================] - 25s 147ms/step - loss: 0.0174 - prec: 0.9921 - rec: 1.0000 - val_loss: 4.5173 - val_prec: 0.7778 - val_rec: 0.7778\n",
      "Epoch 81/100\n",
      "170/170 [==============================] - 25s 149ms/step - loss: 0.0046 - prec: 0.9980 - rec: 1.0000 - val_loss: 4.4706 - val_prec: 0.7241 - val_rec: 0.7778\n",
      "Epoch 82/100\n",
      "170/170 [==============================] - 26s 150ms/step - loss: 0.0403 - prec: 0.9800 - rec: 0.9919 - val_loss: 3.3168 - val_prec: 0.7407 - val_rec: 0.7407\n",
      "Epoch 83/100\n",
      "170/170 [==============================] - 26s 150ms/step - loss: 0.0173 - prec: 0.9939 - rec: 0.9980 - val_loss: 4.0446 - val_prec: 0.7407 - val_rec: 0.7407\n",
      "Epoch 84/100\n",
      "170/170 [==============================] - 26s 151ms/step - loss: 0.0265 - prec: 0.9901 - rec: 0.9960 - val_loss: 2.9068 - val_prec: 0.8400 - val_rec: 0.7778\n",
      "Epoch 85/100\n",
      "170/170 [==============================] - 26s 150ms/step - loss: 0.0157 - prec: 0.9959 - rec: 0.9959 - val_loss: 4.4812 - val_prec: 0.8400 - val_rec: 0.7778\n",
      "Epoch 86/100\n",
      "170/170 [==============================] - 26s 151ms/step - loss: 0.0051 - prec: 0.9980 - rec: 1.0000 - val_loss: 4.8375 - val_prec: 0.8400 - val_rec: 0.7778\n",
      "Epoch 87/100\n",
      "170/170 [==============================] - 25s 149ms/step - loss: 0.0060 - prec: 0.9980 - rec: 1.0000 - val_loss: 5.2740 - val_prec: 0.8400 - val_rec: 0.7778\n",
      "Epoch 88/100\n",
      "170/170 [==============================] - 26s 150ms/step - loss: 0.0149 - prec: 0.9918 - rec: 0.9959 - val_loss: 4.5893 - val_prec: 0.8696 - val_rec: 0.7407\n",
      "Epoch 89/100\n",
      "170/170 [==============================] - 26s 151ms/step - loss: 0.0823 - prec: 0.9860 - rec: 0.9840 - val_loss: 3.0538 - val_prec: 0.7692 - val_rec: 0.7407\n",
      "Epoch 90/100\n",
      "170/170 [==============================] - 25s 150ms/step - loss: 0.2598 - prec: 0.9463 - rec: 0.9597 - val_loss: 1.8142 - val_prec: 0.9091 - val_rec: 0.7407\n",
      "Epoch 91/100\n",
      "170/170 [==============================] - 26s 151ms/step - loss: 0.0721 - prec: 0.9821 - rec: 0.9960 - val_loss: 2.3345 - val_prec: 0.7419 - val_rec: 0.8519\n",
      "Epoch 92/100\n",
      "170/170 [==============================] - 26s 150ms/step - loss: 0.0431 - prec: 0.9823 - rec: 0.9980 - val_loss: 1.7828 - val_prec: 0.8261 - val_rec: 0.7037\n",
      "Epoch 93/100\n",
      "170/170 [==============================] - 26s 151ms/step - loss: 0.0782 - prec: 0.9720 - rec: 0.9898 - val_loss: 3.3722 - val_prec: 0.8400 - val_rec: 0.7778\n",
      "Epoch 94/100\n",
      "170/170 [==============================] - 26s 152ms/step - loss: 0.0109 - prec: 0.9960 - rec: 0.9980 - val_loss: 3.8412 - val_prec: 0.8214 - val_rec: 0.8519\n",
      "Epoch 95/100\n",
      "170/170 [==============================] - 26s 152ms/step - loss: 0.0083 - prec: 0.9940 - rec: 1.0000 - val_loss: 4.0919 - val_prec: 0.8462 - val_rec: 0.8148\n",
      "Epoch 96/100\n",
      "170/170 [==============================] - 26s 151ms/step - loss: 0.0047 - prec: 1.0000 - rec: 1.0000 - val_loss: 4.3711 - val_prec: 0.7931 - val_rec: 0.8519\n",
      "Epoch 97/100\n",
      "170/170 [==============================] - 25s 149ms/step - loss: 0.0038 - prec: 0.9980 - rec: 1.0000 - val_loss: 4.5369 - val_prec: 0.8462 - val_rec: 0.8148\n",
      "Epoch 98/100\n",
      "170/170 [==============================] - 25s 146ms/step - loss: 0.0024 - prec: 1.0000 - rec: 1.0000 - val_loss: 4.9512 - val_prec: 0.8214 - val_rec: 0.8519\n",
      "Epoch 99/100\n",
      "170/170 [==============================] - 25s 147ms/step - loss: 0.0031 - prec: 1.0000 - rec: 1.0000 - val_loss: 5.1038 - val_prec: 0.8214 - val_rec: 0.8519\n",
      "Epoch 100/100\n",
      "170/170 [==============================] - 25s 147ms/step - loss: 0.0029 - prec: 1.0000 - rec: 1.0000 - val_loss: 5.2903 - val_prec: 0.8400 - val_rec: 0.7778\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "# log_dir = f\"{os.environ['tb_path']}segmentation/res50_baseline_bs_128_is_32/\"\n",
    "# if os.path.exists(log_dir) == False:\n",
    "#     os.makedirs(log_dir)\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir)\n",
    "weights_path = f'../../weights_mayo_strip_ai/swin_version_2/'\n",
    "weights_save = CallbackForSavingModelWeights(weights_path)\n",
    "batch_size = 4\n",
    "train_dataset = get_data(train, batch_size=batch_size)\n",
    "val_dataset = get_data(val, shuffle=False, repeat=False, batch_size=batch_size)\n",
    "# model_config_file\n",
    "input_shape = (256, 256, 3)\n",
    "patch_size = (2, 2)\n",
    "num_patch_x = input_shape[0] // patch_size[0]\n",
    "num_patch_y = input_shape[1] // patch_size[1]\n",
    "embed_dim = 64\n",
    "num_heads = 8\n",
    "window_size = 2\n",
    "dropout_rate = 0.0\n",
    "qkv_bias = True\n",
    "num_mlp = 256\n",
    "shift_size = 1\n",
    "with strategy.scope():\n",
    "    model = final_model(input_shape, patch_size, embed_dim, num_heads, window_size, dropout_rate, qkv_bias, num_mlp, shift_size)\n",
    "wandb.init(\n",
    "    project = 'mayo_strip_ai',\n",
    "    # Please add number of epochs\n",
    "    config = {\n",
    "        'input_shape' : input_shape,\n",
    "        'patch_size' : patch_size,\n",
    "        'num_patch_x' : num_patch_x,\n",
    "        'num_patch_y' : num_patch_y, \n",
    "        'embed_dim' : embed_dim,\n",
    "        'num_heads' : num_heads,\n",
    "        'window_size' : window_size,\n",
    "        'dropout_rate' : dropout_rate,\n",
    "        'qkv_bias' : qkv_bias,\n",
    "        'num_mlp' : num_mlp,\n",
    "        'shift_size' : shift_size,\n",
    "        'optim' : model.optimizer,\n",
    "        'batch_size' : batch_size,\n",
    "    }\n",
    ")\n",
    "# model traning loop\n",
    "with strategy.scope():\n",
    "    model_hist = model.fit(\n",
    "        train_dataset,\n",
    "        steps_per_epoch = len(train) // (batch_size * REPLICAS),\n",
    "        epochs = 100,\n",
    "        verbose = 1,\n",
    "        validation_data = val_dataset,\n",
    "        # callbacks = [tensorboard_callback]\n",
    "        callbacks = [\n",
    "            WandbMetricsLogger()\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from incep_model import get_incep_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:juqyq7ou) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▇▇▇▂▁▁▁▁▁▁▁▁▃▁▁▁▁▁▂▂▁▁▁▁▁▁▁▅▂▁▁▁▁▁▂▁▁▁▁</td></tr><tr><td>epoch/prec</td><td>▁▁▁▁▇█▇██████▇▇█████▇███████▃▇██▇███████</td></tr><tr><td>epoch/rec</td><td>▁▅▆▇▇████████▇█████▇▇███████▆██████▇████</td></tr><tr><td>epoch/val_loss</td><td>▁▁▁▁▂▂▁▂▂▃▃▃▄▂▄▄▅▆▆▇▃▅▆▇█▇██▁▄▅▆▅▄█▅▃▆▇█</td></tr><tr><td>epoch/val_prec</td><td>▃▃▃▂▃▅▄▄▄▅▄▅█▃▄▅▅▅▅▂▄▂▄▄▃▅▆▅▁▅▅▃▂▇▇▄▆▆▇▇</td></tr><tr><td>epoch/val_rec</td><td>███▇▅▃▄▅▆▅▃▃▃▅▃▄▄▄▄▇▁▂▄▄▄▄▅▄▅▃▄▄▃▄▄▃▂▅▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.00293</td></tr><tr><td>epoch/prec</td><td>1.0</td></tr><tr><td>epoch/rec</td><td>1.0</td></tr><tr><td>epoch/val_loss</td><td>5.29029</td></tr><tr><td>epoch/val_prec</td><td>0.84</td></tr><tr><td>epoch/val_rec</td><td>0.77778</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fast-sun-16</strong> at: <a href='https://wandb.ai/yashchks87/mayo_strip_ai/runs/juqyq7ou' target=\"_blank\">https://wandb.ai/yashchks87/mayo_strip_ai/runs/juqyq7ou</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230728_163952-juqyq7ou/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:juqyq7ou). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/paperspace/Documents/mayo_strip_ai/notebooks/wandb/run-20230728_172422-08nd6lby</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yashchks87/mayo_strip_ai/runs/08nd6lby' target=\"_blank\">autumn-sea-17</a></strong> to <a href='https://wandb.ai/yashchks87/mayo_strip_ai' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yashchks87/mayo_strip_ai' target=\"_blank\">https://wandb.ai/yashchks87/mayo_strip_ai</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yashchks87/mayo_strip_ai/runs/08nd6lby' target=\"_blank\">https://wandb.ai/yashchks87/mayo_strip_ai/runs/08nd6lby</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "170/170 [==============================] - 48s 121ms/step - loss: 0.7008 - prec: 0.7256 - rec: 0.8690 - val_loss: 0.5657 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 2/100\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.6140 - prec: 0.7449 - rec: 0.9504 - val_loss: 0.5665 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 3/100\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.6056 - prec: 0.7307 - rec: 0.9840 - val_loss: 0.5703 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 4/100\n",
      "170/170 [==============================] - 17s 101ms/step - loss: 0.6332 - prec: 0.7100 - rec: 0.9711 - val_loss: 70.8425 - val_prec: 0.0000e+00 - val_rec: 0.0000e+00\n",
      "Epoch 5/100\n",
      "170/170 [==============================] - 16s 95ms/step - loss: 0.6204 - prec: 0.7241 - rec: 0.9758 - val_loss: 0.6193 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 6/100\n",
      "170/170 [==============================] - 16s 93ms/step - loss: 0.6077 - prec: 0.7282 - rec: 0.9960 - val_loss: 0.5557 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 7/100\n",
      "170/170 [==============================] - 16s 93ms/step - loss: 0.5897 - prec: 0.7396 - rec: 0.9960 - val_loss: 0.5407 - val_prec: 0.7714 - val_rec: 1.0000\n",
      "Epoch 8/100\n",
      "170/170 [==============================] - 16s 93ms/step - loss: 0.5988 - prec: 0.7330 - rec: 0.9818 - val_loss: 0.5530 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 9/100\n",
      "170/170 [==============================] - 16s 93ms/step - loss: 0.5920 - prec: 0.7378 - rec: 0.9980 - val_loss: 1.3463 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 10/100\n",
      "170/170 [==============================] - 16s 93ms/step - loss: 0.6163 - prec: 0.7191 - rec: 0.9632 - val_loss: 0.5599 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 11/100\n",
      "170/170 [==============================] - 16s 95ms/step - loss: 0.5854 - prec: 0.7415 - rec: 0.9960 - val_loss: 0.8955 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 12/100\n",
      "170/170 [==============================] - 16s 96ms/step - loss: 0.5906 - prec: 0.7286 - rec: 0.9838 - val_loss: 0.6127 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 13/100\n",
      "170/170 [==============================] - 16s 94ms/step - loss: 0.6112 - prec: 0.7176 - rec: 1.0000 - val_loss: 0.5655 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 14/100\n",
      "170/170 [==============================] - 16s 93ms/step - loss: 0.5963 - prec: 0.7320 - rec: 0.9980 - val_loss: 0.5502 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 15/100\n",
      "170/170 [==============================] - 16s 95ms/step - loss: 0.5910 - prec: 0.7415 - rec: 0.9881 - val_loss: 0.5665 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 16/100\n",
      "170/170 [==============================] - 16s 94ms/step - loss: 0.6090 - prec: 0.7139 - rec: 0.9670 - val_loss: 0.5808 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 17/100\n",
      "170/170 [==============================] - 16s 93ms/step - loss: 0.6052 - prec: 0.7231 - rec: 0.9777 - val_loss: 3.8589 - val_prec: 0.6957 - val_rec: 0.5926\n",
      "Epoch 18/100\n",
      "170/170 [==============================] - 16s 93ms/step - loss: 0.6142 - prec: 0.7186 - rec: 0.9816 - val_loss: 1.0595 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 19/100\n",
      "170/170 [==============================] - 17s 97ms/step - loss: 0.5885 - prec: 0.7400 - rec: 0.9881 - val_loss: 0.8661 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 20/100\n",
      "170/170 [==============================] - 17s 99ms/step - loss: 0.5794 - prec: 0.7444 - rec: 0.9821 - val_loss: 0.5627 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 21/100\n",
      "170/170 [==============================] - 16s 94ms/step - loss: 0.6163 - prec: 0.7149 - rec: 0.9836 - val_loss: 7.7818 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 22/100\n",
      "170/170 [==============================] - 16s 95ms/step - loss: 0.5755 - prec: 0.7529 - rec: 1.0000 - val_loss: 1.3845 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 23/100\n",
      "170/170 [==============================] - 16s 94ms/step - loss: 0.6189 - prec: 0.7123 - rec: 0.9610 - val_loss: 0.7655 - val_prec: 0.7333 - val_rec: 0.8148\n",
      "Epoch 24/100\n",
      "170/170 [==============================] - 16s 95ms/step - loss: 0.5964 - prec: 0.7309 - rec: 1.0000 - val_loss: 0.5674 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 25/100\n",
      "170/170 [==============================] - 16s 94ms/step - loss: 0.6142 - prec: 0.7202 - rec: 0.9857 - val_loss: 0.7177 - val_prec: 0.7333 - val_rec: 0.4074\n",
      "Epoch 26/100\n",
      "170/170 [==============================] - 16s 95ms/step - loss: 0.5885 - prec: 0.7372 - rec: 0.9761 - val_loss: 1.2466 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 27/100\n",
      "170/170 [==============================] - 16s 95ms/step - loss: 0.6189 - prec: 0.7085 - rec: 0.9710 - val_loss: 0.5756 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 28/100\n",
      "170/170 [==============================] - 16s 94ms/step - loss: 0.5909 - prec: 0.7553 - rec: 0.9709 - val_loss: 5.4349 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 29/100\n",
      "170/170 [==============================] - 16s 94ms/step - loss: 0.6280 - prec: 0.7087 - rec: 0.9752 - val_loss: 2.6110 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 30/100\n",
      "170/170 [==============================] - 16s 94ms/step - loss: 0.5813 - prec: 0.7426 - rec: 1.0000 - val_loss: 0.5630 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 31/100\n",
      "170/170 [==============================] - 16s 93ms/step - loss: 0.5990 - prec: 0.7261 - rec: 1.0000 - val_loss: 0.5672 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 32/100\n",
      "170/170 [==============================] - 16s 93ms/step - loss: 0.5939 - prec: 0.7278 - rec: 0.9919 - val_loss: 0.5706 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 33/100\n",
      "170/170 [==============================] - 16s 94ms/step - loss: 0.5928 - prec: 0.7250 - rec: 1.0000 - val_loss: 0.5595 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 34/100\n",
      "170/170 [==============================] - 16s 93ms/step - loss: 0.6190 - prec: 0.7218 - rec: 0.9836 - val_loss: 0.7248 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 35/100\n",
      "170/170 [==============================] - 16s 94ms/step - loss: 0.5933 - prec: 0.7303 - rec: 0.9859 - val_loss: 5.9002 - val_prec: 0.6000 - val_rec: 0.2222\n",
      "Epoch 36/100\n",
      "170/170 [==============================] - 16s 95ms/step - loss: 0.5942 - prec: 0.7293 - rec: 0.9920 - val_loss: 0.6994 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 37/100\n",
      "170/170 [==============================] - 16s 94ms/step - loss: 0.5735 - prec: 0.7441 - rec: 1.0000 - val_loss: 3.0624 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 38/100\n",
      "170/170 [==============================] - 16s 93ms/step - loss: 0.5948 - prec: 0.7338 - rec: 1.0000 - val_loss: 0.5904 - val_prec: 0.7931 - val_rec: 0.8519\n",
      "Epoch 39/100\n",
      "170/170 [==============================] - 16s 95ms/step - loss: 0.5861 - prec: 0.7294 - rec: 1.0000 - val_loss: 0.7611 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 40/100\n",
      "170/170 [==============================] - 16s 95ms/step - loss: 0.5950 - prec: 0.7250 - rec: 1.0000 - val_loss: 0.7764 - val_prec: 0.7600 - val_rec: 0.7037\n",
      "Epoch 41/100\n",
      "170/170 [==============================] - 16s 95ms/step - loss: 0.6010 - prec: 0.7183 - rec: 0.9959 - val_loss: 0.6570 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 42/100\n",
      "170/170 [==============================] - 16s 95ms/step - loss: 0.5969 - prec: 0.7250 - rec: 1.0000 - val_loss: 0.5611 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 43/100\n",
      "170/170 [==============================] - 16s 95ms/step - loss: 0.5918 - prec: 0.7294 - rec: 1.0000 - val_loss: 0.5660 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 44/100\n",
      "170/170 [==============================] - 16s 97ms/step - loss: 0.5823 - prec: 0.7368 - rec: 1.0000 - val_loss: 0.5624 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 45/100\n",
      "170/170 [==============================] - 17s 98ms/step - loss: 0.6090 - prec: 0.7172 - rec: 0.9980 - val_loss: 0.5274 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 46/100\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.5782 - prec: 0.7426 - rec: 1.0000 - val_loss: 0.5493 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 47/100\n",
      "170/170 [==============================] - 17s 100ms/step - loss: 0.6095 - prec: 0.7162 - rec: 1.0000 - val_loss: 9.5761 - val_prec: 0.7500 - val_rec: 1.0000\n",
      "Epoch 48/100\n",
      "120/170 [====================>.........] - ETA: 4s - loss: 0.5764 - prec: 0.7417 - rec: 1.0000"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "# log_dir = f\"{os.environ['tb_path']}segmentation/res50_baseline_bs_128_is_32/\"\n",
    "# if os.path.exists(log_dir) == False:\n",
    "#     os.makedirs(log_dir)\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir)\n",
    "weights_path = f'../../weights_mayo_strip_ai/incep_v1/'\n",
    "weights_save = CallbackForSavingModelWeights(weights_path)\n",
    "batch_size = 4\n",
    "train_dataset = get_data(train, batch_size=batch_size)\n",
    "val_dataset = get_data(val, shuffle=False, repeat=False, batch_size=batch_size)\n",
    "# model_config_file\n",
    "with strategy.scope():\n",
    "    model = get_incep_model()\n",
    "wandb.init(\n",
    "    project = 'mayo_strip_ai',\n",
    "    # Please add number of epochs\n",
    "    config = {\n",
    "        'model_name' : 'InceptionV3',\n",
    "        # 'input_shape' : input_shape,\n",
    "        # 'patch_size' : patch_size,\n",
    "        # 'num_patch_x' : num_patch_x,\n",
    "        # 'num_patch_y' : num_patch_y, \n",
    "        # 'embed_dim' : embed_dim,\n",
    "        # 'num_heads' : num_heads,\n",
    "        # 'window_size' : window_size,\n",
    "        # 'dropout_rate' : dropout_rate,\n",
    "        # 'qkv_bias' : qkv_bias,\n",
    "        # 'num_mlp' : num_mlp,\n",
    "        # 'shift_size' : shift_size,\n",
    "        'optim' : model.optimizer,\n",
    "        'batch_size' : batch_size,\n",
    "    }\n",
    ")\n",
    "# model traning loop\n",
    "with strategy.scope():\n",
    "    model_hist = model.fit(\n",
    "        train_dataset,\n",
    "        steps_per_epoch = len(train) // (batch_size * REPLICAS),\n",
    "        epochs = 100,\n",
    "        verbose = 1,\n",
    "        validation_data = val_dataset,\n",
    "        # callbacks = [tensorboard_callback]\n",
    "        callbacks = [\n",
    "            WandbMetricsLogger()\n",
    "        ]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_env",
   "language": "python",
   "name": "tensor_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
