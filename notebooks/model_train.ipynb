{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "sys.path.append('../scripts/helper_functions_cv/tensorflow_helpers/')\n",
    "from gpu_starter_mirror_strategy import start_gpus\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.utils import compute_class_weight\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Returning objects as strategy, replicas and auto in same order.\n"
     ]
    }
   ],
   "source": [
    "strategy, REPLICAS, AUTO = start_gpus([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = pd.read_csv('../../files/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>center_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>image_num</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>006388_0</td>\n",
       "      <td>11</td>\n",
       "      <td>006388</td>\n",
       "      <td>0</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>008e5c_0</td>\n",
       "      <td>11</td>\n",
       "      <td>008e5c</td>\n",
       "      <td>0</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00c058_0</td>\n",
       "      <td>11</td>\n",
       "      <td>00c058</td>\n",
       "      <td>0</td>\n",
       "      <td>LAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01adc5_0</td>\n",
       "      <td>11</td>\n",
       "      <td>01adc5</td>\n",
       "      <td>0</td>\n",
       "      <td>LAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>026c97_0</td>\n",
       "      <td>4</td>\n",
       "      <td>026c97</td>\n",
       "      <td>0</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id  center_id patient_id  image_num label\n",
       "0  006388_0         11     006388          0    CE\n",
       "1  008e5c_0         11     008e5c          0    CE\n",
       "2  00c058_0         11     00c058          0   LAA\n",
       "3  01adc5_0         11     01adc5          0   LAA\n",
       "4  026c97_0          4     026c97          0    CE"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file['updated_paths'] = csv_file['image_id'].apply(lambda x: '../../files/resized_train_1024/' + x + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in csv_file['updated_paths'].values.tolist():\n",
    "    if os.path.exists(x) == False:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_csv = csv_file[['patient_id', 'label', 'updated_paths']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_csv = updated_csv.groupby('patient_id', as_index = False).agg(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_datasets(data, test_size = 0.1):\n",
    "    train, test = train_test_split(data, test_size=test_size)\n",
    "    train, val = train_test_split(train, test_size=test_size)\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = split_datasets(updated_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 511\n",
      "Val: 57\n",
      "Test: 64\n"
     ]
    }
   ],
   "source": [
    "print(f'Train: {len(train)}')\n",
    "print(f'Val: {len(val)}')\n",
    "print(f'Test: {len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_final_data(csv_file):\n",
    "    labels = csv_file['label'].values.tolist()\n",
    "    paths = csv_file['updated_paths'].values.tolist()\n",
    "    labels_, paths_ = [], []\n",
    "    for x in labels:\n",
    "        for y in x:\n",
    "            if y == 'LAA':\n",
    "                labels_.append(np.float32(1))\n",
    "            else:\n",
    "                labels_.append(np.float32(0))\n",
    "    for x in paths:\n",
    "        for y in x:\n",
    "            paths_.append(y)\n",
    "    return labels_, paths_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_images(img, label):\n",
    "    img = tf.io.read_file(img)\n",
    "    img = tf.image.decode_jpeg(img, channels = 3)\n",
    "    img  = tf.image.random_flip_left_right(img)\n",
    "    return img, label\n",
    "def read_images(img, label):\n",
    "    img = tf.io.read_file(img)\n",
    "    img = tf.image.decode_jpeg(img, channels = 3)\n",
    "    img = img / 255\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(csv_file, train=True, repeat = True, shuffle = True, batch = True, batch_size = 64, prefetch = True):\n",
    "    labels, imgs = give_final_data(csv_file)\n",
    "    tensor = tf.data.Dataset.from_tensor_slices((imgs, labels))\n",
    "    tensor = tensor.cache()\n",
    "    if repeat:\n",
    "        tensor = tensor.repeat()\n",
    "    if shuffle:\n",
    "        tensor = tensor.shuffle(1024 * REPLICAS)\n",
    "        opt = tf.data.Options()\n",
    "        opt.experimental_deterministic = False\n",
    "        tensor = tensor.with_options(opt)\n",
    "    if train:\n",
    "        tensor = tensor.map(read_train_images, num_parallel_calls = AUTO)\n",
    "    else:    \n",
    "        tensor = tensor.map(read_images, num_parallel_calls = AUTO)\n",
    "    if batch:\n",
    "        tensor = tensor.batch(batch_size * REPLICAS)\n",
    "    if prefetch:\n",
    "        tensor = tensor.prefetch(AUTO)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_name, size):\n",
    "    input_layer = keras.Input((size, size, 3))\n",
    "    construct = getattr(keras.applications, model_name)\n",
    "    main_layer = construct(include_top = False,\n",
    "                           weights = None,\n",
    "                           pooling = 'avg')(input_layer)\n",
    "    last_layer = keras.layers.Dense(1, activation='sigmoid')(main_layer)\n",
    "    model = keras.Model(input_layer, last_layer)\n",
    "    return model\n",
    "def compile_new_model(model):\n",
    "    with strategy.scope():\n",
    "        loss = keras.losses.BinaryCrossentropy()\n",
    "        optimier = keras.optimizers.SGD()\n",
    "        model.compile(\n",
    "            loss = loss,\n",
    "            optimizer = optimier,\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m tb_callback \u001b[39m=\u001b[39m TensorBoard(log_dir\u001b[39m=\u001b[39mtb_path)\n\u001b[1;32m      7\u001b[0m \u001b[39mwith\u001b[39;00m strategy\u001b[39m.\u001b[39mscope():\n\u001b[0;32m----> 8\u001b[0m     model \u001b[39m=\u001b[39m create_model(\u001b[39m'\u001b[39;49m\u001b[39mResNet50\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m256\u001b[39;49m)\n\u001b[1;32m      9\u001b[0m     model \u001b[39m=\u001b[39m compile_new_model(model)\n\u001b[1;32m     10\u001b[0m train_dataset \u001b[39m=\u001b[39m get_data(train, batch_size\u001b[39m=\u001b[39mbatch_size)\n",
      "Cell \u001b[0;32mIn[28], line 4\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(model_name, size)\u001b[0m\n\u001b[1;32m      2\u001b[0m input_layer \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mInput((size, size, \u001b[39m3\u001b[39m))\n\u001b[1;32m      3\u001b[0m construct \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(keras\u001b[39m.\u001b[39mapplications, model_name)\n\u001b[0;32m----> 4\u001b[0m main_layer \u001b[39m=\u001b[39m construct(include_top \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m      5\u001b[0m                        weights \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m      6\u001b[0m                        pooling \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mavg\u001b[39;49m\u001b[39m'\u001b[39;49m)(input_layer)\n\u001b[1;32m      7\u001b[0m last_layer \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m1\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m'\u001b[39m)(main_layer)\n\u001b[1;32m      8\u001b[0m model \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mModel(input_layer, last_layer)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/keras/engine/training.py:557\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39mcopied_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[1;32m    555\u001b[0m     layout_map_lib\u001b[39m.\u001b[39m_map_subclass_model_variable(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layout_map)\n\u001b[0;32m--> 557\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/keras/engine/base_layer.py:1011\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[39m# Functional Model construction mode is invoked when `Layer`s are called\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m \u001b[39m# on symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m \u001b[39m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[1;32m   1006\u001b[0m \u001b[39m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m \u001b[39m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m \u001b[39mif\u001b[39;00m _in_functional_construction_mode(\n\u001b[1;32m   1009\u001b[0m     \u001b[39mself\u001b[39m, inputs, args, kwargs, input_list\n\u001b[1;32m   1010\u001b[0m ):\n\u001b[0;32m-> 1011\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_functional_construction_call(\n\u001b[1;32m   1012\u001b[0m         inputs, args, kwargs, input_list\n\u001b[1;32m   1013\u001b[0m     )\n\u001b[1;32m   1015\u001b[0m \u001b[39m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m call_context \u001b[39m=\u001b[39m base_layer_utils\u001b[39m.\u001b[39mcall_context()\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/keras/engine/base_layer.py:2498\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   2491\u001b[0m         training_arg_passed_by_framework \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m call_context\u001b[39m.\u001b[39menter(\n\u001b[1;32m   2494\u001b[0m     layer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, inputs\u001b[39m=\u001b[39minputs, build_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39mtraining_value\n\u001b[1;32m   2495\u001b[0m ):\n\u001b[1;32m   2496\u001b[0m     \u001b[39m# Check input assumptions set after layer building, e.g. input\u001b[39;00m\n\u001b[1;32m   2497\u001b[0m     \u001b[39m# shape.\u001b[39;00m\n\u001b[0;32m-> 2498\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_keras_tensor_symbolic_call(\n\u001b[1;32m   2499\u001b[0m         inputs, input_masks, args, kwargs\n\u001b[1;32m   2500\u001b[0m     )\n\u001b[1;32m   2502\u001b[0m     \u001b[39mif\u001b[39;00m outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2503\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2504\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mA layer\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms `call` method should return a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2505\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTensor or a list of Tensors, not None \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2506\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m(layer: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2507\u001b[0m         )\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/keras/engine/base_layer.py:2345\u001b[0m, in \u001b[0;36mLayer._keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m   2341\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m   2342\u001b[0m         keras_tensor\u001b[39m.\u001b[39mKerasTensor, output_signature\n\u001b[1;32m   2343\u001b[0m     )\n\u001b[1;32m   2344\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2345\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_infer_output_signature(\n\u001b[1;32m   2346\u001b[0m         inputs, args, kwargs, input_masks\n\u001b[1;32m   2347\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/keras/engine/base_layer.py:2404\u001b[0m, in \u001b[0;36mLayer._infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m   2402\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_build(inputs)\n\u001b[1;32m   2403\u001b[0m         inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs)\n\u001b[0;32m-> 2404\u001b[0m         outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2406\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n\u001b[1;32m   2407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_mask_metadata(\n\u001b[1;32m   2408\u001b[0m     inputs, outputs, input_masks, build_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   2409\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/keras/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/keras/engine/functional.py:510\u001b[0m, in \u001b[0;36mFunctional.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[39m@doc_controls\u001b[39m\u001b[39m.\u001b[39mdo_not_doc_inheritable\n\u001b[1;32m    492\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs, training\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    493\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \n\u001b[1;32m    495\u001b[0m \u001b[39m    In this case `call` just reapplies\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[39m        a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 510\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_internal_graph(inputs, training\u001b[39m=\u001b[39;49mtraining, mask\u001b[39m=\u001b[39;49mmask)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/keras/engine/functional.py:667\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    664\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[1;32m    666\u001b[0m args, kwargs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[0;32m--> 667\u001b[0m outputs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39;49mlayer(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    669\u001b[0m \u001b[39m# Update tensor_dict.\u001b[39;00m\n\u001b[1;32m    670\u001b[0m \u001b[39mfor\u001b[39;00m x_id, y \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\n\u001b[1;32m    671\u001b[0m     node\u001b[39m.\u001b[39mflat_output_ids, tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(outputs)\n\u001b[1;32m    672\u001b[0m ):\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/keras/engine/base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1094\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1096\u001b[0m ):\n\u001b[0;32m-> 1097\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/keras/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/keras/layers/normalization/batch_normalization.py:850\u001b[0m, in \u001b[0;36mBatchNormalizationBase.call\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[39mreturn\u001b[39;00m outputs\n\u001b[1;32m    849\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfused:\n\u001b[0;32m--> 850\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fused_batch_norm(inputs, training\u001b[39m=\u001b[39;49mtraining)\n\u001b[1;32m    851\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvirtual_batch_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    852\u001b[0m         \u001b[39m# Currently never reaches here since fused_batch_norm does not\u001b[39;00m\n\u001b[1;32m    853\u001b[0m         \u001b[39m# support virtual batching\u001b[39;00m\n\u001b[1;32m    854\u001b[0m         outputs \u001b[39m=\u001b[39m undo_virtual_batching(outputs)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/keras/layers/normalization/batch_normalization.py:660\u001b[0m, in \u001b[0;36mBatchNormalizationBase._fused_batch_norm\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fused_batch_norm_inference\u001b[39m():\n\u001b[1;32m    649\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfused_batch_norm(\n\u001b[1;32m    650\u001b[0m         inputs,\n\u001b[1;32m    651\u001b[0m         gamma,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    657\u001b[0m         data_format\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_format,\n\u001b[1;32m    658\u001b[0m     )\n\u001b[0;32m--> 660\u001b[0m output, mean, variance \u001b[39m=\u001b[39m control_flow_util\u001b[39m.\u001b[39;49msmart_cond(\n\u001b[1;32m    661\u001b[0m     training, _fused_batch_norm_training, _fused_batch_norm_inference\n\u001b[1;32m    662\u001b[0m )\n\u001b[1;32m    663\u001b[0m variance \u001b[39m=\u001b[39m _maybe_add_or_remove_bessels_correction(\n\u001b[1;32m    664\u001b[0m     variance, remove\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    665\u001b[0m )\n\u001b[1;32m    667\u001b[0m training_value \u001b[39m=\u001b[39m control_flow_util\u001b[39m.\u001b[39mconstant_value(training)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/keras/utils/control_flow_util.py:108\u001b[0m, in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(pred, tf\u001b[39m.\u001b[39mVariable):\n\u001b[1;32m    107\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mcond(pred, true_fn\u001b[39m=\u001b[39mtrue_fn, false_fn\u001b[39m=\u001b[39mfalse_fn, name\u001b[39m=\u001b[39mname)\n\u001b[0;32m--> 108\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49m__internal__\u001b[39m.\u001b[39;49msmart_cond\u001b[39m.\u001b[39;49msmart_cond(\n\u001b[1;32m    109\u001b[0m     pred, true_fn\u001b[39m=\u001b[39;49mtrue_fn, false_fn\u001b[39m=\u001b[39;49mfalse_fn, name\u001b[39m=\u001b[39;49mname\n\u001b[1;32m    110\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/framework/smart_cond.py:54\u001b[0m, in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[39mreturn\u001b[39;00m true_fn()\n\u001b[1;32m     53\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m false_fn()\n\u001b[1;32m     55\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     56\u001b[0m   \u001b[39mreturn\u001b[39;00m control_flow_ops\u001b[39m.\u001b[39mcond(pred, true_fn\u001b[39m=\u001b[39mtrue_fn, false_fn\u001b[39m=\u001b[39mfalse_fn,\n\u001b[1;32m     57\u001b[0m                                name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/keras/layers/normalization/batch_normalization.py:649\u001b[0m, in \u001b[0;36mBatchNormalizationBase._fused_batch_norm.<locals>._fused_batch_norm_inference\u001b[0;34m()\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fused_batch_norm_inference\u001b[39m():\n\u001b[0;32m--> 649\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mcompat\u001b[39m.\u001b[39;49mv1\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mfused_batch_norm(\n\u001b[1;32m    650\u001b[0m         inputs,\n\u001b[1;32m    651\u001b[0m         gamma,\n\u001b[1;32m    652\u001b[0m         beta,\n\u001b[1;32m    653\u001b[0m         mean\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmoving_mean,\n\u001b[1;32m    654\u001b[0m         variance\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmoving_variance,\n\u001b[1;32m    655\u001b[0m         epsilon\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepsilon,\n\u001b[1;32m    656\u001b[0m         is_training\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    657\u001b[0m         data_format\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_format,\n\u001b[1;32m    658\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/ops/nn_impl.py:1691\u001b[0m, in \u001b[0;36mfused_batch_norm\u001b[0;34m(x, scale, offset, mean, variance, epsilon, data_format, is_training, name, exponential_avg_factor)\u001b[0m\n\u001b[1;32m   1688\u001b[0m min_epsilon \u001b[39m=\u001b[39m \u001b[39m1.001e-5\u001b[39m\n\u001b[1;32m   1689\u001b[0m epsilon \u001b[39m=\u001b[39m epsilon \u001b[39mif\u001b[39;00m epsilon \u001b[39m>\u001b[39m min_epsilon \u001b[39melse\u001b[39;00m min_epsilon\n\u001b[0;32m-> 1691\u001b[0m y, running_mean, running_var, _, _, _ \u001b[39m=\u001b[39m gen_nn_ops\u001b[39m.\u001b[39;49mfused_batch_norm_v3(\n\u001b[1;32m   1692\u001b[0m     x,\n\u001b[1;32m   1693\u001b[0m     scale,\n\u001b[1;32m   1694\u001b[0m     offset,\n\u001b[1;32m   1695\u001b[0m     mean,\n\u001b[1;32m   1696\u001b[0m     variance,\n\u001b[1;32m   1697\u001b[0m     epsilon\u001b[39m=\u001b[39;49mepsilon,\n\u001b[1;32m   1698\u001b[0m     exponential_avg_factor\u001b[39m=\u001b[39;49mexponential_avg_factor,\n\u001b[1;32m   1699\u001b[0m     data_format\u001b[39m=\u001b[39;49mdata_format,\n\u001b[1;32m   1700\u001b[0m     is_training\u001b[39m=\u001b[39;49mis_training,\n\u001b[1;32m   1701\u001b[0m     name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m   1702\u001b[0m \u001b[39mreturn\u001b[39;00m y, running_mean, running_var\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/ops/gen_nn_ops.py:4505\u001b[0m, in \u001b[0;36mfused_batch_norm_v3\u001b[0;34m(x, scale, offset, mean, variance, epsilon, exponential_avg_factor, data_format, is_training, name)\u001b[0m\n\u001b[1;32m   4503\u001b[0m   is_training \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   4504\u001b[0m is_training \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39mmake_bool(is_training, \u001b[39m\"\u001b[39m\u001b[39mis_training\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 4505\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[1;32m   4506\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mFusedBatchNormV3\u001b[39;49m\u001b[39m\"\u001b[39;49m, x\u001b[39m=\u001b[39;49mx, scale\u001b[39m=\u001b[39;49mscale, offset\u001b[39m=\u001b[39;49moffset, mean\u001b[39m=\u001b[39;49mmean,\n\u001b[1;32m   4507\u001b[0m                           variance\u001b[39m=\u001b[39;49mvariance, epsilon\u001b[39m=\u001b[39;49mepsilon,\n\u001b[1;32m   4508\u001b[0m                           exponential_avg_factor\u001b[39m=\u001b[39;49mexponential_avg_factor,\n\u001b[1;32m   4509\u001b[0m                           data_format\u001b[39m=\u001b[39;49mdata_format, is_training\u001b[39m=\u001b[39;49mis_training,\n\u001b[1;32m   4510\u001b[0m                           name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m   4511\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[1;32m   4512\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:779\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m g\u001b[39m.\u001b[39mas_default(), ops\u001b[39m.\u001b[39mname_scope(name) \u001b[39mas\u001b[39;00m scope:\n\u001b[1;32m    778\u001b[0m   \u001b[39mif\u001b[39;00m fallback:\n\u001b[0;32m--> 779\u001b[0m     _ExtractInputsAndAttrs(op_type_name, op_def, allowed_list_attr_map,\n\u001b[1;32m    780\u001b[0m                            keywords, default_type_attr_map, attrs, inputs,\n\u001b[1;32m    781\u001b[0m                            input_types)\n\u001b[1;32m    782\u001b[0m     _ExtractRemainingAttrs(op_type_name, op_def, keywords,\n\u001b[1;32m    783\u001b[0m                            default_type_attr_map, attrs)\n\u001b[1;32m    784\u001b[0m     _ExtractAttrProto(op_type_name, op_def, attrs, attr_protos)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:552\u001b[0m, in \u001b[0;36m_ExtractInputsAndAttrs\u001b[0;34m(op_type_name, op_def, allowed_list_attr_map, keywords, default_type_attr_map, attrs, inputs, input_types)\u001b[0m\n\u001b[1;32m    546\u001b[0m       values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(\n\u001b[1;32m    547\u001b[0m           values,\n\u001b[1;32m    548\u001b[0m           name\u001b[39m=\u001b[39minput_arg\u001b[39m.\u001b[39mname,\n\u001b[1;32m    549\u001b[0m           as_ref\u001b[39m=\u001b[39minput_arg\u001b[39m.\u001b[39mis_ref,\n\u001b[1;32m    550\u001b[0m           preferred_dtype\u001b[39m=\u001b[39mdefault_dtype)\n\u001b[1;32m    551\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 552\u001b[0m     values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mconvert_to_tensor(\n\u001b[1;32m    553\u001b[0m         values,\n\u001b[1;32m    554\u001b[0m         name\u001b[39m=\u001b[39;49minput_arg\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    555\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    556\u001b[0m         as_ref\u001b[39m=\u001b[39;49minput_arg\u001b[39m.\u001b[39;49mis_ref,\n\u001b[1;32m    557\u001b[0m         preferred_dtype\u001b[39m=\u001b[39;49mdefault_dtype)\n\u001b[1;32m    558\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    559\u001b[0m   \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1638\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1629\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1630\u001b[0m           _add_error_prefix(\n\u001b[1;32m   1631\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConversion function \u001b[39m\u001b[39m{\u001b[39;00mconversion_func\u001b[39m!r}\u001b[39;00m\u001b[39m for type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1634\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mactual = \u001b[39m\u001b[39m{\u001b[39;00mret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1635\u001b[0m               name\u001b[39m=\u001b[39mname))\n\u001b[1;32m   1637\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1638\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[1;32m   1640\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[1;32m   1641\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/distribute/values.py:1402\u001b[0m, in \u001b[0;36m_tensor_conversion_distributed_var\u001b[0;34m(var, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1398\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_tensor_conversion_distributed_var\u001b[39m(var,\n\u001b[1;32m   1399\u001b[0m                                        dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1400\u001b[0m                                        name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1401\u001b[0m                                        as_ref\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m-> 1402\u001b[0m   \u001b[39mreturn\u001b[39;00m var\u001b[39m.\u001b[39;49m_dense_var_to_tensor(dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/distribute/values.py:1392\u001b[0m, in \u001b[0;36mSyncOnReadVariable._dense_var_to_tensor\u001b[0;34m(self, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1383\u001b[0m   reduced \u001b[39m=\u001b[39m (\n\u001b[1;32m   1384\u001b[0m       replica_context\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mextended\u001b[39m.\u001b[39m_replica_ctx_all_reduce(\n\u001b[1;32m   1385\u001b[0m           reduce_util\u001b[39m.\u001b[39mReduceOp\u001b[39m.\u001b[39mfrom_variable_aggregation(\n\u001b[1;32m   1386\u001b[0m               \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aggregation),\n\u001b[1;32m   1387\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get()\u001b[39m.\u001b[39mread_value()))\n\u001b[1;32m   1388\u001b[0m   \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39mconvert_to_tensor(\n\u001b[1;32m   1389\u001b[0m       reduced, dtype\u001b[39m=\u001b[39mdtype, name\u001b[39m=\u001b[39mname, as_ref\u001b[39m=\u001b[39mas_ref)\n\u001b[1;32m   1391\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39mconvert_to_tensor(\n\u001b[0;32m-> 1392\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get(), dtype\u001b[39m=\u001b[39mdtype, name\u001b[39m=\u001b[39mname, as_ref\u001b[39m=\u001b[39mas_ref)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/distribute/values.py:1225\u001b[0m, in \u001b[0;36mSyncOnReadVariable._get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns the value of SyncOnReadVariable based on surrounding context.\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m \n\u001b[1;32m   1219\u001b[0m \u001b[39mIf called under a non-default replica-context, returns the corresponding\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[39mthe synced value.\u001b[39;00m\n\u001b[1;32m   1223\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1224\u001b[0m \u001b[39mwith\u001b[39;00m ds_context\u001b[39m.\u001b[39menter_or_assert_strategy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_distribute_strategy):\n\u001b[0;32m-> 1225\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(SyncOnReadVariable, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_get()\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/distribute/values.py:729\u001b[0m, in \u001b[0;36mDistributedVariable._get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    727\u001b[0m replica_id \u001b[39m=\u001b[39m values_util\u001b[39m.\u001b[39mget_current_replica_id_as_int()\n\u001b[1;32m    728\u001b[0m \u001b[39mif\u001b[39;00m replica_id \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 729\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_cross_replica()\n\u001b[1;32m    730\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_replica(replica_id)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/distribute/values.py:1339\u001b[0m, in \u001b[0;36mSyncOnReadVariable._get_cross_replica\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1337\u001b[0m   values_util\u001b[39m.\u001b[39mmark_as_unsaveable()\n\u001b[1;32m   1338\u001b[0m \u001b[39mwith\u001b[39;00m ds_context\u001b[39m.\u001b[39menter_or_assert_strategy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_distribute_strategy):\n\u001b[0;32m-> 1339\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_distribute_strategy\u001b[39m.\u001b[39;49mreduce(\n\u001b[1;32m   1340\u001b[0m       reduce_util\u001b[39m.\u001b[39;49mReduceOp\u001b[39m.\u001b[39;49mfrom_variable_aggregation(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_aggregation),\n\u001b[1;32m   1341\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1342\u001b[0m       axis\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1427\u001b[0m, in \u001b[0;36mStrategyBase.reduce\u001b[0;34m(self, reduce_op, value, axis)\u001b[0m\n\u001b[1;32m   1425\u001b[0m   reduce_op \u001b[39m=\u001b[39m reduce_util\u001b[39m.\u001b[39mReduceOp(reduce_op\u001b[39m.\u001b[39mupper())\n\u001b[1;32m   1426\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1427\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49m_reduce(reduce_op, value)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1428\u001b[0m \u001b[39mif\u001b[39;00m reduce_op \u001b[39m==\u001b[39m reduce_util\u001b[39m.\u001b[39mReduceOp\u001b[39m.\u001b[39mSUM:\n\u001b[1;32m   1430\u001b[0m   \u001b[39mdef\u001b[39;00m \u001b[39mreduce_sum\u001b[39m(v):\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2299\u001b[0m, in \u001b[0;36mStrategyExtendedV2._reduce\u001b[0;34m(self, reduce_op, value)\u001b[0m\n\u001b[1;32m   2296\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_reduce\u001b[39m(\u001b[39mself\u001b[39m, reduce_op, value):\n\u001b[1;32m   2297\u001b[0m   \u001b[39m# Default implementation until we have an implementation for each strategy.\u001b[39;00m\n\u001b[1;32m   2298\u001b[0m   dst \u001b[39m=\u001b[39m device_util\u001b[39m.\u001b[39mcurrent() \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_default_device \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m/device:CPU:0\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 2299\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_results(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduce_to(reduce_op, value, dst))[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2384\u001b[0m, in \u001b[0;36mStrategyExtendedV2.reduce_to\u001b[0;34m(self, reduce_op, value, destinations, options)\u001b[0m\n\u001b[1;32m   2381\u001b[0m   reduce_op \u001b[39m=\u001b[39m reduce_util\u001b[39m.\u001b[39mReduceOp(reduce_op\u001b[39m.\u001b[39mupper())\n\u001b[1;32m   2382\u001b[0m \u001b[39massert\u001b[39;00m (reduce_op \u001b[39m==\u001b[39m reduce_util\u001b[39m.\u001b[39mReduceOp\u001b[39m.\u001b[39mSUM \u001b[39mor\u001b[39;00m\n\u001b[1;32m   2383\u001b[0m         reduce_op \u001b[39m==\u001b[39m reduce_util\u001b[39m.\u001b[39mReduceOp\u001b[39m.\u001b[39mMEAN)\n\u001b[0;32m-> 2384\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reduce_to(reduce_op, value, destinations, options)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_strategy.py:755\u001b[0m, in \u001b[0;36mMirroredExtended._reduce_to\u001b[0;34m(self, reduce_op, value, destinations, options)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[39mreturn\u001b[39;00m cross_device_ops_lib\u001b[39m.\u001b[39mReductionToOneDevice()\u001b[39m.\u001b[39mreduce(\n\u001b[1;32m    748\u001b[0m         reduce_op, value, destinations)\n\u001b[1;32m    749\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_cross_device_ops(value)\u001b[39m.\u001b[39mreduce(\n\u001b[1;32m    750\u001b[0m       reduce_op,\n\u001b[1;32m    751\u001b[0m       value,\n\u001b[1;32m    752\u001b[0m       destinations\u001b[39m=\u001b[39mdestinations,\n\u001b[1;32m    753\u001b[0m       options\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_communication_options\u001b[39m.\u001b[39mmerge(options))\n\u001b[0;32m--> 755\u001b[0m \u001b[39mreturn\u001b[39;00m nest\u001b[39m.\u001b[39;49mmap_structure(get_values, value)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_strategy.py:749\u001b[0m, in \u001b[0;36mMirroredExtended._reduce_to.<locals>.get_values\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_merge_call() \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_collective_ops_in_use \u001b[39mand\u001b[39;00m ((\n\u001b[1;32m    744\u001b[0m     \u001b[39mnot\u001b[39;00m cross_device_ops_lib\u001b[39m.\u001b[39m_devices_match(value, destinations) \u001b[39mor\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    745\u001b[0m     \u001b[39many\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m d\u001b[39m.\u001b[39mlower()\n\u001b[1;32m    746\u001b[0m         \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m cross_device_ops_lib\u001b[39m.\u001b[39mget_devices_from(destinations)))):\n\u001b[1;32m    747\u001b[0m   \u001b[39mreturn\u001b[39;00m cross_device_ops_lib\u001b[39m.\u001b[39mReductionToOneDevice()\u001b[39m.\u001b[39mreduce(\n\u001b[1;32m    748\u001b[0m       reduce_op, value, destinations)\n\u001b[0;32m--> 749\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_cross_device_ops(value)\u001b[39m.\u001b[39;49mreduce(\n\u001b[1;32m    750\u001b[0m     reduce_op,\n\u001b[1;32m    751\u001b[0m     value,\n\u001b[1;32m    752\u001b[0m     destinations\u001b[39m=\u001b[39;49mdestinations,\n\u001b[1;32m    753\u001b[0m     options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_communication_options\u001b[39m.\u001b[39;49mmerge(options))\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/distribute/cross_device_ops.py:317\u001b[0m, in \u001b[0;36mCrossDeviceOps.reduce\u001b[0;34m(self, reduce_op, per_replica_value, destinations, options)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39mif\u001b[39;00m options \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m   options \u001b[39m=\u001b[39m collective_util\u001b[39m.\u001b[39mOptions()\n\u001b[0;32m--> 317\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduce_implementation(reduce_op, per_replica_value,\n\u001b[1;32m    318\u001b[0m                                   destinations, options)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/distribute/cross_device_ops.py:865\u001b[0m, in \u001b[0;36mAllReduceCrossDeviceOps.reduce_implementation\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    863\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_all_reduce(reduce_op, [per_replica_value])[\u001b[39m0\u001b[39m]\n\u001b[1;32m    864\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 865\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_simple_cross_replica_ops\u001b[39m.\u001b[39;49mreduce(reduce_op, per_replica_value,\n\u001b[1;32m    866\u001b[0m                                                destinations)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/distribute/cross_device_ops.py:317\u001b[0m, in \u001b[0;36mCrossDeviceOps.reduce\u001b[0;34m(self, reduce_op, per_replica_value, destinations, options)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39mif\u001b[39;00m options \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m   options \u001b[39m=\u001b[39m collective_util\u001b[39m.\u001b[39mOptions()\n\u001b[0;32m--> 317\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduce_implementation(reduce_op, per_replica_value,\n\u001b[1;32m    318\u001b[0m                                   destinations, options)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/distribute/cross_device_ops.py:619\u001b[0m, in \u001b[0;36mReductionToOneDevice.reduce_implementation\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    615\u001b[0m reduce_to_device \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreduce_to_device \u001b[39mor\u001b[39;00m devices[\u001b[39m0\u001b[39m]\n\u001b[1;32m    616\u001b[0m logging\u001b[39m.\u001b[39mlog_first_n(\n\u001b[1;32m    617\u001b[0m     logging\u001b[39m.\u001b[39mINFO,\n\u001b[1;32m    618\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mReduce to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m then broadcast to \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (reduce_to_device, devices), \u001b[39m10\u001b[39m)\n\u001b[0;32m--> 619\u001b[0m reduced \u001b[39m=\u001b[39m _simple_reduce(per_replica_value, reduce_to_device,\n\u001b[1;32m    620\u001b[0m                          \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maccumulation_fn, reduce_op)\n\u001b[1;32m    621\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbroadcast(reduced, destinations)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/distribute/cross_device_ops.py:226\u001b[0m, in \u001b[0;36m_simple_reduce\u001b[0;34m(per_replica_value, reduce_to_device, accumulation_fn, reduce_op)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mdevice(reduce_to_device):\n\u001b[1;32m    225\u001b[0m   \u001b[39mwith\u001b[39;00m context\u001b[39m.\u001b[39mdevice_policy(context\u001b[39m.\u001b[39mDEVICE_PLACEMENT_SILENT):\n\u001b[0;32m--> 226\u001b[0m     reduced \u001b[39m=\u001b[39m cross_device_utils\u001b[39m.\u001b[39;49maggregate_tensors_or_indexed_slices(\n\u001b[1;32m    227\u001b[0m         all_values, accumulation_fn)\n\u001b[1;32m    228\u001b[0m     \u001b[39mif\u001b[39;00m reduce_op \u001b[39m==\u001b[39m reduce_util\u001b[39m.\u001b[39mReduceOp\u001b[39m.\u001b[39mMEAN:\n\u001b[1;32m    229\u001b[0m       reduced \u001b[39m=\u001b[39m cross_device_utils\u001b[39m.\u001b[39mdivide_by_n_tensors_or_indexed_slices(\n\u001b[1;32m    230\u001b[0m           reduced, count)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/distribute/cross_device_utils.py:580\u001b[0m, in \u001b[0;36maggregate_tensors_or_indexed_slices\u001b[0;34m(values, accumulation_fn)\u001b[0m\n\u001b[1;32m    578\u001b[0m   \u001b[39mreturn\u001b[39;00m backprop\u001b[39m.\u001b[39maggregate_indexed_slices_gradients(values)\n\u001b[1;32m    579\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 580\u001b[0m   \u001b[39mreturn\u001b[39;00m accumulation_fn(values)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:4044\u001b[0m, in \u001b[0;36madd_n\u001b[0;34m(inputs, name)\u001b[0m\n\u001b[1;32m   4041\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m inputs \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(inputs, collections_abc\u001b[39m.\u001b[39mIterable):\n\u001b[1;32m   4042\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInputs must be an iterable of at least one \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4043\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39mTensor/IndexedSlices with the same dtype and shape.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 4044\u001b[0m inputs \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mconvert_n_to_tensor_or_indexed_slices(inputs)\n\u001b[1;32m   4045\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[1;32m   4046\u001b[0m     \u001b[39misinstance\u001b[39m(x, (ops\u001b[39m.\u001b[39mTensor, indexed_slices\u001b[39m.\u001b[39mIndexedSlices))\n\u001b[1;32m   4047\u001b[0m     \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m inputs):\n\u001b[1;32m   4048\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInputs must be an iterable of at least one \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4049\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39mTensor/IndexedSlices with the same dtype and shape.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:394\u001b[0m, in \u001b[0;36mconvert_n_to_tensor_or_indexed_slices\u001b[0;34m(values, dtype, name)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert_n_to_tensor_or_indexed_slices\u001b[39m(values, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    372\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Converts `values` to a list of `Output` or `IndexedSlices` objects.\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \n\u001b[1;32m    374\u001b[0m \u001b[39m  Any `IndexedSlices` or `SparseTensor` objects in `values` are returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[39m      value.\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 394\u001b[0m   \u001b[39mreturn\u001b[39;00m internal_convert_n_to_tensor_or_indexed_slices(\n\u001b[1;32m    395\u001b[0m       values\u001b[39m=\u001b[39;49mvalues, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:366\u001b[0m, in \u001b[0;36minternal_convert_n_to_tensor_or_indexed_slices\u001b[0;34m(values, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    363\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    364\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (name, i)\n\u001b[1;32m    365\u001b[0m     ret\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> 366\u001b[0m         internal_convert_to_tensor_or_indexed_slices(\n\u001b[1;32m    367\u001b[0m             value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mn, as_ref\u001b[39m=\u001b[39;49mas_ref))\n\u001b[1;32m    368\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/framework/indexed_slices.py:327\u001b[0m, in \u001b[0;36minternal_convert_to_tensor_or_indexed_slices\u001b[0;34m(value, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    325\u001b[0m   \u001b[39mreturn\u001b[39;00m value\n\u001b[1;32m    326\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m   \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mconvert_to_tensor(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1638\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1629\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1630\u001b[0m           _add_error_prefix(\n\u001b[1;32m   1631\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConversion function \u001b[39m\u001b[39m{\u001b[39;00mconversion_func\u001b[39m!r}\u001b[39;00m\u001b[39m for type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1634\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mactual = \u001b[39m\u001b[39m{\u001b[39;00mret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1635\u001b[0m               name\u001b[39m=\u001b[39mname))\n\u001b[1;32m   1637\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1638\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[1;32m   1640\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[1;32m   1641\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:2105\u001b[0m, in \u001b[0;36m_dense_var_to_tensor\u001b[0;34m(var, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   2104\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_dense_var_to_tensor\u001b[39m(var, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, as_ref\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m-> 2105\u001b[0m   \u001b[39mreturn\u001b[39;00m var\u001b[39m.\u001b[39;49m_dense_var_to_tensor(dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:1467\u001b[0m, in \u001b[0;36mBaseResourceVariable._dense_var_to_tensor\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1465\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_value()\u001b[39m.\u001b[39mop\u001b[39m.\u001b[39minputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1466\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1467\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue()\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:582\u001b[0m, in \u001b[0;36mBaseResourceVariable.value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    580\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_value\n\u001b[1;32m    581\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcolocate_with(\u001b[39mNone\u001b[39;00m, ignore_existing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 582\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_variable_op()\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:704\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[0;34m(self, no_copy)\u001b[0m\n\u001b[1;32m    702\u001b[0m       result \u001b[39m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[1;32m    703\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m   result \u001b[39m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[1;32m    706\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    707\u001b[0m   \u001b[39m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[1;32m    708\u001b[0m   \u001b[39m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[1;32m    709\u001b[0m   tape\u001b[39m.\u001b[39mrecord_operation(\n\u001b[1;32m    710\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mReadVariableOp\u001b[39m\u001b[39m\"\u001b[39m, [result], [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle],\n\u001b[1;32m    711\u001b[0m       backward_function\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: [x],\n\u001b[1;32m    712\u001b[0m       forward_function\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:694\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[0;34m(no_copy)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[39mif\u001b[39;00m no_copy \u001b[39mand\u001b[39;00m forward_compat\u001b[39m.\u001b[39mforward_compatible(\u001b[39m2022\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m3\u001b[39m):\n\u001b[1;32m    693\u001b[0m   gen_resource_variable_ops\u001b[39m.\u001b[39mdisable_copy_on_read(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle)\n\u001b[0;32m--> 694\u001b[0m result \u001b[39m=\u001b[39m gen_resource_variable_ops\u001b[39m.\u001b[39;49mread_variable_op(\n\u001b[1;32m    695\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dtype)\n\u001b[1;32m    696\u001b[0m _maybe_set_handle_data(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dtype, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle, result)\n\u001b[1;32m    697\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py:539\u001b[0m, in \u001b[0;36mread_variable_op\u001b[0;34m(resource, dtype, name)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m    538\u001b[0m dtype \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39mmake_type(dtype, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 539\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[1;32m    540\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mReadVariableOp\u001b[39;49m\u001b[39m\"\u001b[39;49m, resource\u001b[39m=\u001b[39;49mresource, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m    541\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[1;32m    542\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:779\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m g\u001b[39m.\u001b[39mas_default(), ops\u001b[39m.\u001b[39mname_scope(name) \u001b[39mas\u001b[39;00m scope:\n\u001b[1;32m    778\u001b[0m   \u001b[39mif\u001b[39;00m fallback:\n\u001b[0;32m--> 779\u001b[0m     _ExtractInputsAndAttrs(op_type_name, op_def, allowed_list_attr_map,\n\u001b[1;32m    780\u001b[0m                            keywords, default_type_attr_map, attrs, inputs,\n\u001b[1;32m    781\u001b[0m                            input_types)\n\u001b[1;32m    782\u001b[0m     _ExtractRemainingAttrs(op_type_name, op_def, keywords,\n\u001b[1;32m    783\u001b[0m                            default_type_attr_map, attrs)\n\u001b[1;32m    784\u001b[0m     _ExtractAttrProto(op_type_name, op_def, attrs, attr_protos)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:552\u001b[0m, in \u001b[0;36m_ExtractInputsAndAttrs\u001b[0;34m(op_type_name, op_def, allowed_list_attr_map, keywords, default_type_attr_map, attrs, inputs, input_types)\u001b[0m\n\u001b[1;32m    546\u001b[0m       values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(\n\u001b[1;32m    547\u001b[0m           values,\n\u001b[1;32m    548\u001b[0m           name\u001b[39m=\u001b[39minput_arg\u001b[39m.\u001b[39mname,\n\u001b[1;32m    549\u001b[0m           as_ref\u001b[39m=\u001b[39minput_arg\u001b[39m.\u001b[39mis_ref,\n\u001b[1;32m    550\u001b[0m           preferred_dtype\u001b[39m=\u001b[39mdefault_dtype)\n\u001b[1;32m    551\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 552\u001b[0m     values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mconvert_to_tensor(\n\u001b[1;32m    553\u001b[0m         values,\n\u001b[1;32m    554\u001b[0m         name\u001b[39m=\u001b[39;49minput_arg\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    555\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    556\u001b[0m         as_ref\u001b[39m=\u001b[39;49minput_arg\u001b[39m.\u001b[39;49mis_ref,\n\u001b[1;32m    557\u001b[0m         preferred_dtype\u001b[39m=\u001b[39;49mdefault_dtype)\n\u001b[1;32m    558\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    559\u001b[0m   \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1593\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1587\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m graph\u001b[39m.\u001b[39mbuilding_function:\n\u001b[1;32m   1588\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1589\u001b[0m           _add_error_prefix(\n\u001b[1;32m   1590\u001b[0m               \u001b[39m\"\u001b[39m\u001b[39mAttempting to capture an EagerTensor without \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1591\u001b[0m               \u001b[39m\"\u001b[39m\u001b[39mbuilding a function.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1592\u001b[0m               name\u001b[39m=\u001b[39mname))\n\u001b[0;32m-> 1593\u001b[0m     \u001b[39mreturn\u001b[39;00m graph\u001b[39m.\u001b[39;49mcapture(value, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m   1595\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1596\u001b[0m   dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:771\u001b[0m, in \u001b[0;36mFuncGraph.capture\u001b[0;34m(self, tensor, name, shape)\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture_eager_tensor(tensor, name)\n\u001b[1;32m    770\u001b[0m   \u001b[39m# Large EagerTensors and resources are captured with Placeholder ops\u001b[39;00m\n\u001b[0;32m--> 771\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_helper(tensor, name, shape)\n\u001b[1;32m    772\u001b[0m \u001b[39mif\u001b[39;00m tensor\u001b[39m.\u001b[39mgraph \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m    773\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:806\u001b[0m, in \u001b[0;36mFuncGraph._capture_helper\u001b[0;34m(self, tensor, name, shape)\u001b[0m\n\u001b[1;32m    804\u001b[0m capture \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_captures\u001b[39m.\u001b[39mget(\u001b[39mid\u001b[39m(tensor))\n\u001b[1;32m    805\u001b[0m \u001b[39mif\u001b[39;00m capture \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 806\u001b[0m   placeholder \u001b[39m=\u001b[39m _create_substitute_placeholder(\n\u001b[1;32m    807\u001b[0m       tensor, name\u001b[39m=\u001b[39;49mname, dtype\u001b[39m=\u001b[39;49mtensor\u001b[39m.\u001b[39;49mdtype, shape\u001b[39m=\u001b[39;49mshape)\n\u001b[1;32m    808\u001b[0m   \u001b[39m# Record the composite device as an attribute to the placeholder.\u001b[39;00m\n\u001b[1;32m    809\u001b[0m   \u001b[39m# This attribute would be propogated into the arg_attr of the FunctionDef.\u001b[39;00m\n\u001b[1;32m    810\u001b[0m   \u001b[39m# Currently, a packed eager tensor is always placed on a CompositeDevice.\u001b[39;00m\n\u001b[1;32m    811\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(tensor, ops\u001b[39m.\u001b[39mEagerTensor) \u001b[39mand\u001b[39;00m tensor\u001b[39m.\u001b[39mis_packed:\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1420\u001b[0m, in \u001b[0;36m_create_substitute_placeholder\u001b[0;34m(value, name, dtype, shape)\u001b[0m\n\u001b[1;32m   1418\u001b[0m   shape \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39mshape\n\u001b[1;32m   1419\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcontrol_dependencies(\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1420\u001b[0m   placeholder \u001b[39m=\u001b[39m graph_placeholder(\n\u001b[1;32m   1421\u001b[0m       dtype\u001b[39m=\u001b[39;49mdtype \u001b[39mor\u001b[39;49;00m value\u001b[39m.\u001b[39;49mdtype, shape\u001b[39m=\u001b[39;49mshape, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m   1422\u001b[0m handle_data_util\u001b[39m.\u001b[39mcopy_handle_data(value, placeholder)\n\u001b[1;32m   1423\u001b[0m \u001b[39mreturn\u001b[39;00m placeholder\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/eager/graph_only_ops.py:34\u001b[0m, in \u001b[0;36mgraph_placeholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m     32\u001b[0m g \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\n\u001b[1;32m     33\u001b[0m attrs \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m: dtype_value, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m: shape}\n\u001b[0;32m---> 34\u001b[0m op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m     35\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mPlaceholder\u001b[39;49m\u001b[39m\"\u001b[39;49m, [], [dtype], input_types\u001b[39m=\u001b[39;49m[],\n\u001b[1;32m     36\u001b[0m     attrs\u001b[39m=\u001b[39;49mattrs, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m     37\u001b[0m result, \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n\u001b[1;32m     38\u001b[0m \u001b[39mif\u001b[39;00m op_callbacks\u001b[39m.\u001b[39mshould_invoke_op_callbacks():\n\u001b[1;32m     39\u001b[0m   \u001b[39m# TODO(b/147670703): Once the special-op creation code paths\u001b[39;00m\n\u001b[1;32m     40\u001b[0m   \u001b[39m# are unified. Remove this `if` block.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:735\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    733\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[1;32m    734\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[0;32m--> 735\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(FuncGraph, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    736\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[1;32m    737\u001b[0m     compute_device)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:3800\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3797\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[0;32m-> 3800\u001b[0m   ret \u001b[39m=\u001b[39m Operation(\n\u001b[1;32m   3801\u001b[0m       node_def,\n\u001b[1;32m   3802\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   3803\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[1;32m   3804\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[1;32m   3805\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[1;32m   3806\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[1;32m   3807\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[1;32m   3808\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[1;32m   3809\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[1;32m   3810\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2108\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   2105\u001b[0m     control_input_ops\u001b[39m.\u001b[39mappend(control_op)\n\u001b[1;32m   2107\u001b[0m \u001b[39m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[0;32m-> 2108\u001b[0m c_op \u001b[39m=\u001b[39m _create_c_op(g, node_def, inputs, control_input_ops, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[1;32m   2109\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_from_c_op(c_op\u001b[39m=\u001b[39mc_op, g\u001b[39m=\u001b[39mg)\n\u001b[1;32m   2111\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_op \u001b[39m=\u001b[39m original_op\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/tensor_env/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1966\u001b[0m, in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[1;32m   1962\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39mTF_SetAttrValueProto(op_desc, compat\u001b[39m.\u001b[39mas_str(name),\n\u001b[1;32m   1963\u001b[0m                                          serialized)\n\u001b[1;32m   1965\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1966\u001b[0m   c_op \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_FinishOperation(op_desc)\n\u001b[1;32m   1967\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mInvalidArgumentError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1968\u001b[0m   \u001b[39m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[1;32m   1969\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(e\u001b[39m.\u001b[39mmessage)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "batch_size = 32\n",
    "tb_path = '../TB/res50_baseline_bs_32_is_256/'\n",
    "if os.path.exists(tb_path) == False:\n",
    "    os.makedirs(tb_path)\n",
    "tb_callback = TensorBoard(log_dir=tb_path)\n",
    "with strategy.scope():\n",
    "    model = create_model('ResNet50', 256)\n",
    "    model = compile_new_model(model)\n",
    "train_dataset = get_data(train, batch_size=batch_size)\n",
    "val_dataset = get_data(val, repeat=False, batch_size=batch_size)\n",
    "modelhist = model.fit(\n",
    "    train_dataset,\n",
    "    epochs = 20, \n",
    "    verbose = 1,\n",
    "    validation_data = val_dataset,\n",
    "    steps_per_epoch = len(train) // (REPLICAS * batch_size),\n",
    "    callbacks = [tb_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "15/15 [==============================] - 15s 153ms/step - loss: 0.6296 - val_loss: 0.6735\n",
      "Epoch 2/20\n",
      "15/15 [==============================] - 1s 65ms/step - loss: 0.5987 - val_loss: 0.6520\n",
      "Epoch 3/20\n",
      "15/15 [==============================] - 1s 90ms/step - loss: 0.5778 - val_loss: 0.6398\n",
      "Epoch 4/20\n",
      "15/15 [==============================] - 1s 63ms/step - loss: 0.5798 - val_loss: 0.6333\n",
      "Epoch 5/20\n",
      "15/15 [==============================] - 1s 67ms/step - loss: 0.5970 - val_loss: 0.6195\n",
      "Epoch 6/20\n",
      "15/15 [==============================] - 1s 65ms/step - loss: 0.6321 - val_loss: 0.6146\n",
      "Epoch 7/20\n",
      "15/15 [==============================] - 1s 66ms/step - loss: 0.5704 - val_loss: 0.6053\n",
      "Epoch 8/20\n",
      "15/15 [==============================] - 1s 69ms/step - loss: 0.5804 - val_loss: 0.6014\n",
      "Epoch 9/20\n",
      "15/15 [==============================] - 1s 63ms/step - loss: 0.5375 - val_loss: 0.5993\n",
      "Epoch 10/20\n",
      "15/15 [==============================] - 1s 62ms/step - loss: 0.5913 - val_loss: 0.5998\n",
      "Epoch 11/20\n",
      "15/15 [==============================] - 1s 61ms/step - loss: 0.5423 - val_loss: 0.5989\n",
      "Epoch 12/20\n",
      "15/15 [==============================] - 1s 61ms/step - loss: 0.5864 - val_loss: 0.5967\n",
      "Epoch 13/20\n",
      "15/15 [==============================] - 1s 65ms/step - loss: 0.5824 - val_loss: 0.5967\n",
      "Epoch 14/20\n",
      "15/15 [==============================] - 1s 63ms/step - loss: 0.5644 - val_loss: 0.5994\n",
      "Epoch 15/20\n",
      "15/15 [==============================] - 1s 62ms/step - loss: 0.5169 - val_loss: 0.6254\n",
      "Epoch 16/20\n",
      "15/15 [==============================] - 1s 61ms/step - loss: 0.5319 - val_loss: 0.6488\n",
      "Epoch 17/20\n",
      "15/15 [==============================] - 1s 63ms/step - loss: 0.5369 - val_loss: 0.6285\n",
      "Epoch 18/20\n",
      "15/15 [==============================] - 1s 61ms/step - loss: 0.5089 - val_loss: 0.6807\n",
      "Epoch 19/20\n",
      "15/15 [==============================] - 1s 64ms/step - loss: 0.5081 - val_loss: 0.6484\n",
      "Epoch 20/20\n",
      "15/15 [==============================] - 1s 62ms/step - loss: 0.5440 - val_loss: 0.6041\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "batch_size = 32\n",
    "tb_path = '../TB/incep_baseline_bs_32_is_256/'\n",
    "if os.path.exists(tb_path) == False:\n",
    "    os.makedirs(tb_path)\n",
    "tb_callback = TensorBoard(log_dir=tb_path)\n",
    "with strategy.scope():\n",
    "    model = create_model('InceptionV3', 256)\n",
    "    model = compile_new_model(model)\n",
    "train_dataset = get_data(train, batch_size=batch_size)\n",
    "val_dataset = get_data(val, repeat=False, batch_size=batch_size)\n",
    "modelhist = model.fit(\n",
    "    train_dataset,\n",
    "    epochs = 20, \n",
    "    verbose = 1,\n",
    "    validation_data = val_dataset,\n",
    "    steps_per_epoch = len(train) // (REPLICAS * batch_size),\n",
    "    callbacks = [tb_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "15/15 [==============================] - 10s 234ms/step - loss: 0.6060 - val_loss: 0.6884\n",
      "Epoch 2/20\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 0.5777 - val_loss: 0.6873\n",
      "Epoch 3/20\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 0.5409 - val_loss: 0.6854\n",
      "Epoch 4/20\n",
      "15/15 [==============================] - 2s 113ms/step - loss: 0.5704 - val_loss: 0.6855\n",
      "Epoch 5/20\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 0.5416 - val_loss: 0.6836\n",
      "Epoch 6/20\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 0.5294 - val_loss: 0.6830\n",
      "Epoch 7/20\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.4732 - val_loss: 0.6802\n",
      "Epoch 8/20\n",
      "15/15 [==============================] - 2s 113ms/step - loss: 0.5343 - val_loss: 0.6808\n",
      "Epoch 9/20\n",
      "15/15 [==============================] - 2s 115ms/step - loss: 0.4678 - val_loss: 0.6791\n",
      "Epoch 10/20\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 0.4445 - val_loss: 0.6760\n",
      "Epoch 11/20\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 0.4491 - val_loss: 0.6725\n",
      "Epoch 12/20\n",
      "15/15 [==============================] - 2s 113ms/step - loss: 0.4261 - val_loss: 0.6702\n",
      "Epoch 13/20\n",
      "15/15 [==============================] - 2s 113ms/step - loss: 0.3369 - val_loss: 0.6659\n",
      "Epoch 14/20\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 0.3494 - val_loss: 0.6638\n",
      "Epoch 15/20\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 0.3768 - val_loss: 0.6623\n",
      "Epoch 16/20\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 0.2954 - val_loss: 0.6569\n",
      "Epoch 17/20\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 0.2043 - val_loss: 0.6521\n",
      "Epoch 18/20\n",
      "15/15 [==============================] - 2s 114ms/step - loss: 0.1594 - val_loss: 0.6454\n",
      "Epoch 19/20\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 0.1578 - val_loss: 0.6382\n",
      "Epoch 20/20\n",
      "15/15 [==============================] - 2s 113ms/step - loss: 0.1149 - val_loss: 0.6357\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "batch_size = 32\n",
    "tb_path = '../TB/xcep_baseline_bs_32_is_256/'\n",
    "if os.path.exists(tb_path) == False:\n",
    "    os.makedirs(tb_path)\n",
    "tb_callback = TensorBoard(log_dir=tb_path)\n",
    "with strategy.scope():\n",
    "    model = create_model('Xception', 256)\n",
    "    model = compile_new_model(model)\n",
    "train_dataset = get_data(train, train=False, batch_size=batch_size)\n",
    "val_dataset = get_data(val, train = False, repeat=False, batch_size=batch_size)\n",
    "modelhist = model.fit(\n",
    "    train_dataset,\n",
    "    epochs = 20, \n",
    "    verbose = 1,\n",
    "    validation_data = val_dataset,\n",
    "    steps_per_epoch = len(train) // (REPLICAS * batch_size),\n",
    "    callbacks = [tb_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "15/15 [==============================] - 10s 232ms/step - loss: 0.5905 - val_loss: 0.6893\n",
      "Epoch 2/20\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 0.5922 - val_loss: 0.6881\n",
      "Epoch 3/20\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 0.5884 - val_loss: 0.6870\n",
      "Epoch 4/20\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 0.5541 - val_loss: 0.6841\n",
      "Epoch 5/20\n",
      "15/15 [==============================] - 2s 114ms/step - loss: 0.5641 - val_loss: 0.6831\n",
      "Epoch 6/20\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 0.5429 - val_loss: 0.6811\n",
      "Epoch 7/20\n",
      "15/15 [==============================] - 2s 113ms/step - loss: 0.5551 - val_loss: 0.6790\n",
      "Epoch 8/20\n",
      "15/15 [==============================] - 2s 114ms/step - loss: 0.5454 - val_loss: 0.6772\n",
      "Epoch 9/20\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 0.4994 - val_loss: 0.6739\n",
      "Epoch 10/20\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 0.5280 - val_loss: 0.6728\n",
      "Epoch 11/20\n",
      "15/15 [==============================] - 2s 113ms/step - loss: 0.5104 - val_loss: 0.6697\n",
      "Epoch 12/20\n",
      "15/15 [==============================] - 2s 114ms/step - loss: 0.5370 - val_loss: 0.6690\n",
      "Epoch 13/20\n",
      "15/15 [==============================] - 2s 114ms/step - loss: 0.4772 - val_loss: 0.6659\n",
      "Epoch 14/20\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 0.4411 - val_loss: 0.6625\n",
      "Epoch 15/20\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 0.4661 - val_loss: 0.6618\n",
      "Epoch 16/20\n",
      "15/15 [==============================] - 2s 114ms/step - loss: 0.4527 - val_loss: 0.6599\n",
      "Epoch 17/20\n",
      "15/15 [==============================] - 2s 114ms/step - loss: 0.4160 - val_loss: 0.6578\n",
      "Epoch 18/20\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 0.4657 - val_loss: 0.6573\n",
      "Epoch 19/20\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 0.4001 - val_loss: 0.6567\n",
      "Epoch 20/20\n",
      "15/15 [==============================] - 2s 113ms/step - loss: 0.4427 - val_loss: 0.6512\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "batch_size = 32\n",
    "tb_path = '../TB/xcep_baseline_bs_32_is_256_i_flip/'\n",
    "if os.path.exists(tb_path) == False:\n",
    "    os.makedirs(tb_path)\n",
    "tb_callback = TensorBoard(log_dir=tb_path)\n",
    "with strategy.scope():\n",
    "    model = create_model('Xception', 256)\n",
    "    model = compile_new_model(model)\n",
    "train_dataset = get_data(train, batch_size=batch_size)\n",
    "val_dataset = get_data(val, train=False, repeat=False, shuffle=False, batch_size=batch_size)\n",
    "modelhist = model.fit(\n",
    "    train_dataset,\n",
    "    epochs = 20, \n",
    "    verbose = 1,\n",
    "    validation_data = val_dataset,\n",
    "    steps_per_epoch = len(train) // (REPLICAS * batch_size),\n",
    "    callbacks = [tb_callback]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class weights calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_coded = []\n",
    "for x in train['label']:\n",
    "    for y in x:\n",
    "        if y == \"LAA\":\n",
    "            label_coded.append(np.float32(1.0))\n",
    "        else:\n",
    "            label_coded.append(np.float32(0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_weights = compute_class_weight(class_weight='balanced', classes=[0,1], y = label_coded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = dict(zip([0, 1], computed_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "15/15 [==============================] - 10s 234ms/step - loss: 0.6844 - val_loss: 0.6930\n",
      "Epoch 2/20\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 0.6843 - val_loss: 0.6928\n",
      "Epoch 3/20\n",
      "15/15 [==============================] - 2s 109ms/step - loss: 0.6826 - val_loss: 0.6930\n",
      "Epoch 4/20\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 0.6643 - val_loss: 0.6922\n",
      "Epoch 5/20\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 0.6281 - val_loss: 0.6900\n",
      "Epoch 6/20\n",
      "15/15 [==============================] - 2s 109ms/step - loss: 0.6587 - val_loss: 0.6918\n",
      "Epoch 7/20\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 0.6543 - val_loss: 0.6912\n",
      "Epoch 8/20\n",
      "15/15 [==============================] - 2s 109ms/step - loss: 0.6302 - val_loss: 0.6894\n",
      "Epoch 9/20\n",
      "15/15 [==============================] - 2s 114ms/step - loss: 0.5730 - val_loss: 0.6857\n",
      "Epoch 10/20\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 0.6022 - val_loss: 0.6850\n",
      "Epoch 11/20\n",
      "15/15 [==============================] - 2s 114ms/step - loss: 0.5669 - val_loss: 0.6821\n",
      "Epoch 12/20\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 0.5342 - val_loss: 0.6808\n",
      "Epoch 13/20\n",
      "15/15 [==============================] - 2s 115ms/step - loss: 0.5506 - val_loss: 0.6793\n",
      "Epoch 14/20\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 0.6155 - val_loss: 0.6822\n",
      "Epoch 15/20\n",
      "15/15 [==============================] - 2s 115ms/step - loss: 0.5275 - val_loss: 0.6758\n",
      "Epoch 16/20\n",
      "15/15 [==============================] - 2s 113ms/step - loss: 0.5460 - val_loss: 0.6739\n",
      "Epoch 17/20\n",
      "15/15 [==============================] - 2s 114ms/step - loss: 0.4375 - val_loss: 0.6710\n",
      "Epoch 18/20\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 0.5217 - val_loss: 0.6673\n",
      "Epoch 19/20\n",
      "15/15 [==============================] - 2s 113ms/step - loss: 0.4509 - val_loss: 0.6618\n",
      "Epoch 20/20\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 0.3876 - val_loss: 0.6660\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "batch_size = 32\n",
    "tb_path = '../TB/xcep_baseline_bs_32_is_256_i_flip_cw/'\n",
    "if os.path.exists(tb_path) == False:\n",
    "    os.makedirs(tb_path)\n",
    "tb_callback = TensorBoard(log_dir=tb_path)\n",
    "with strategy.scope():\n",
    "    model = create_model('Xception', 256)\n",
    "    model = compile_new_model(model)\n",
    "train_dataset = get_data(train, batch_size=batch_size)\n",
    "val_dataset = get_data(val, train=False, repeat=False, shuffle=False, batch_size=batch_size)\n",
    "modelhist = model.fit(\n",
    "    train_dataset,\n",
    "    epochs = 20, \n",
    "    verbose = 1,\n",
    "    validation_data = val_dataset,\n",
    "    steps_per_epoch = len(train) // (REPLICAS * batch_size),\n",
    "    callbacks = [tb_callback],\n",
    "    class_weight=weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "63/63 [==============================] - 38s 473ms/step - loss: 0.6174 - val_loss: 0.6843\n",
      "Epoch 2/20\n",
      "63/63 [==============================] - 28s 444ms/step - loss: 0.5959 - val_loss: 0.6780\n",
      "Epoch 3/20\n",
      "63/63 [==============================] - 28s 448ms/step - loss: 0.5110 - val_loss: 0.6678\n",
      "Epoch 4/20\n",
      "63/63 [==============================] - 28s 444ms/step - loss: 0.5745 - val_loss: 0.6622\n",
      "Epoch 5/20\n",
      "63/63 [==============================] - 28s 444ms/step - loss: 0.5692 - val_loss: 0.6535\n",
      "Epoch 6/20\n",
      "63/63 [==============================] - 28s 449ms/step - loss: 0.5727 - val_loss: 0.6481\n",
      "Epoch 7/20\n",
      "63/63 [==============================] - 28s 445ms/step - loss: 0.6005 - val_loss: 0.6386\n",
      "Epoch 8/20\n",
      "63/63 [==============================] - 28s 449ms/step - loss: 0.5379 - val_loss: 0.6299\n",
      "Epoch 9/20\n",
      "63/63 [==============================] - 28s 444ms/step - loss: 0.5534 - val_loss: 0.6361\n",
      "Epoch 10/20\n",
      "63/63 [==============================] - 28s 450ms/step - loss: 0.5377 - val_loss: 0.6364\n",
      "Epoch 11/20\n",
      "63/63 [==============================] - 28s 448ms/step - loss: 0.5349 - val_loss: 0.6674\n",
      "Epoch 12/20\n",
      "63/63 [==============================] - 28s 450ms/step - loss: 0.5929 - val_loss: 0.6617\n",
      "Epoch 13/20\n",
      "63/63 [==============================] - 28s 449ms/step - loss: 0.5432 - val_loss: 0.6408\n",
      "Epoch 14/20\n",
      "63/63 [==============================] - 28s 447ms/step - loss: 0.5619 - val_loss: 0.6354\n",
      "Epoch 15/20\n",
      "63/63 [==============================] - 28s 449ms/step - loss: 0.5416 - val_loss: 0.6785\n",
      "Epoch 16/20\n",
      "63/63 [==============================] - 28s 448ms/step - loss: 0.5555 - val_loss: 2.1094\n",
      "Epoch 17/20\n",
      "63/63 [==============================] - 28s 446ms/step - loss: 0.5582 - val_loss: 0.7093\n",
      "Epoch 18/20\n",
      "63/63 [==============================] - 28s 445ms/step - loss: 0.5219 - val_loss: 1.0184\n",
      "Epoch 19/20\n",
      "63/63 [==============================] - 28s 447ms/step - loss: 0.5534 - val_loss: 0.7257\n",
      "Epoch 20/20\n",
      "63/63 [==============================] - 28s 447ms/step - loss: 0.5658 - val_loss: 0.6755\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "batch_size = 8\n",
    "tb_path = '../TB/xcep_baseline_bs_8_is_1024_i_flip_cw/'\n",
    "if os.path.exists(tb_path) == False:\n",
    "    os.makedirs(tb_path)\n",
    "tb_callback = TensorBoard(log_dir=tb_path)\n",
    "with strategy.scope():\n",
    "    model = create_model('Xception', 1024)\n",
    "    model = compile_new_model(model)\n",
    "train_dataset = get_data(train, train=False, batch_size=batch_size)\n",
    "val_dataset = get_data(val, train=False, repeat=False, shuffle=False, batch_size=batch_size)\n",
    "modelhist = model.fit(\n",
    "    train_dataset,\n",
    "    epochs = 20,  \n",
    "    verbose = 1,\n",
    "    validation_data = val_dataset,\n",
    "    steps_per_epoch = len(train) // (REPLICAS * batch_size),\n",
    "    callbacks = [tb_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "batch_size = 8\n",
    "tb_path = '../TB/xcep_baseline_bs_8_is_1024_i_flip_cw/'\n",
    "if os.path.exists(tb_path) == False:\n",
    "    os.makedirs(tb_path)\n",
    "tb_callback = TensorBoard(log_dir=tb_path)\n",
    "with strategy.scope():\n",
    "    model = create_model('Xception', 1024)\n",
    "    model = compile_new_model(model)\n",
    "train_dataset = get_data(train, train=False, batch_size=batch_size)\n",
    "val_dataset = get_data(val, train=False, repeat=False, shuffle=False, batch_size=batch_size)\n",
    "modelhist = model.fit(\n",
    "    train_dataset,\n",
    "    epochs = 20, \n",
    "    verbose = 1,\n",
    "    validation_data = val_dataset,\n",
    "    steps_per_epoch = len(train) // (REPLICAS * batch_size),\n",
    "    callbacks = [tb_callback]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_env",
   "language": "python",
   "name": "tensor_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
