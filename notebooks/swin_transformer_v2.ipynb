{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import glob\n",
    "import PIL, cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "sys.path.append('../scripts/')\n",
    "sys.path.append('../scripts/helper_functions_cv/tensorflow_helpers/')\n",
    "from save_weights_every_epoch import CallbackForSavingModelWeights\n",
    "from swin_transformer import final_model\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow.keras.backend as K\n",
    "import wandb\n",
    "from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "allowed_gpus = [0]\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "final_gpu_list = [gpus[x] for x in allowed_gpus]\n",
    "tf.config.set_visible_devices(final_gpu_list, 'GPU')\n",
    "for gpu in final_gpu_list:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "REPLICAS = strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = pd.read_csv('../../files/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>center_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>image_num</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>006388_0</td>\n",
       "      <td>11</td>\n",
       "      <td>006388</td>\n",
       "      <td>0</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>008e5c_0</td>\n",
       "      <td>11</td>\n",
       "      <td>008e5c</td>\n",
       "      <td>0</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00c058_0</td>\n",
       "      <td>11</td>\n",
       "      <td>00c058</td>\n",
       "      <td>0</td>\n",
       "      <td>LAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01adc5_0</td>\n",
       "      <td>11</td>\n",
       "      <td>01adc5</td>\n",
       "      <td>0</td>\n",
       "      <td>LAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>026c97_0</td>\n",
       "      <td>4</td>\n",
       "      <td>026c97</td>\n",
       "      <td>0</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id  center_id patient_id  image_num label\n",
       "0  006388_0         11     006388          0    CE\n",
       "1  008e5c_0         11     008e5c          0    CE\n",
       "2  00c058_0         11     00c058          0   LAA\n",
       "3  01adc5_0         11     01adc5          0   LAA\n",
       "4  026c97_0          4     026c97          0    CE"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file['fixed_paths'] = csv_file['image_id'].apply(lambda x: '../../files/resized_train/' + x + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>center_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>image_num</th>\n",
       "      <th>label</th>\n",
       "      <th>fixed_paths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>006388_0</td>\n",
       "      <td>11</td>\n",
       "      <td>006388</td>\n",
       "      <td>0</td>\n",
       "      <td>CE</td>\n",
       "      <td>../../files/resized_train/006388_0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>008e5c_0</td>\n",
       "      <td>11</td>\n",
       "      <td>008e5c</td>\n",
       "      <td>0</td>\n",
       "      <td>CE</td>\n",
       "      <td>../../files/resized_train/008e5c_0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00c058_0</td>\n",
       "      <td>11</td>\n",
       "      <td>00c058</td>\n",
       "      <td>0</td>\n",
       "      <td>LAA</td>\n",
       "      <td>../../files/resized_train/00c058_0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01adc5_0</td>\n",
       "      <td>11</td>\n",
       "      <td>01adc5</td>\n",
       "      <td>0</td>\n",
       "      <td>LAA</td>\n",
       "      <td>../../files/resized_train/01adc5_0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>026c97_0</td>\n",
       "      <td>4</td>\n",
       "      <td>026c97</td>\n",
       "      <td>0</td>\n",
       "      <td>CE</td>\n",
       "      <td>../../files/resized_train/026c97_0.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id  center_id patient_id  image_num label   \n",
       "0  006388_0         11     006388          0    CE  \\\n",
       "1  008e5c_0         11     008e5c          0    CE   \n",
       "2  00c058_0         11     00c058          0   LAA   \n",
       "3  01adc5_0         11     01adc5          0   LAA   \n",
       "4  026c97_0          4     026c97          0    CE   \n",
       "\n",
       "                              fixed_paths  \n",
       "0  ../../files/resized_train/006388_0.png  \n",
       "1  ../../files/resized_train/008e5c_0.png  \n",
       "2  ../../files/resized_train/00c058_0.png  \n",
       "3  ../../files/resized_train/01adc5_0.png  \n",
       "4  ../../files/resized_train/026c97_0.png  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in csv_file['fixed_paths'].values:\n",
    "    if os.path.exists(x) == False:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_datasets(csv_file, test_size = 0.01):\n",
    "    train, test = train_test_split(csv_file, test_size=test_size)\n",
    "    train, val = train_test_split(train, test_size=test_size)\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "print(27 / (27 + 9))\n",
    "print(9 / (27 + 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7205882352941176\n",
      "0.27941176470588236\n"
     ]
    }
   ],
   "source": [
    "print(490 / (490 + 190))\n",
    "print(190 / (490 + 190))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_imgs(img, label):\n",
    "    img = tf.io.read_file(img)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    # img = tf.image.random_flip_up_down(img)\n",
    "    img = img / 255\n",
    "    return img, label\n",
    "\n",
    "def read_test_imgs(img, label):\n",
    "    img = tf.io.read_file(img)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    img = img / 255\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(csv_file, train, repeat=True, shuffle=True, batch=True, batch_size=16):\n",
    "    imgs, labels = csv_file['fixed_paths'].values.tolist(), [1 if x == 'CE' else 0 for x in csv_file['label'].values.tolist()]\n",
    "    tensor = tf.data.Dataset.from_tensor_slices((imgs, labels))\n",
    "    tensor = tensor.cache()\n",
    "    if repeat:\n",
    "        tensor = tensor.repeat()\n",
    "    if shuffle:\n",
    "        tensor = tensor.shuffle(256 * REPLICAS)\n",
    "        opt = tf.data.Options()\n",
    "        opt.experimental_deterministic = False\n",
    "        tensor = tensor.with_options(opt)\n",
    "    if train == True:\n",
    "        tensor = tensor.map(read_train_imgs, num_parallel_calls=AUTO)\n",
    "    else:\n",
    "        tensor = tensor.map(read_test_imgs, num_parallel_calls=AUTO)\n",
    "    if batch:\n",
    "        tensor = tensor.batch(batch_size * REPLICAS)\n",
    "    tensor = tensor.prefetch(AUTO)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = split_datasets(csv_file, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = get_data(train)\n",
    "# val_dataset = get_data(val)\n",
    "# test_dataset = get_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (256, 256, 3)\n",
    "patch_size = (2,2)\n",
    "num_patch_x = input_shape[0] // patch_size[0]\n",
    "num_patch_y = input_shape[1] // patch_size[1]\n",
    "embed_dim = 64\n",
    "num_heads = 8\n",
    "window_size = 2\n",
    "dropout_rate = 0.0\n",
    "qkv_bias = True\n",
    "num_mlp = 256\n",
    "shift_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr = np.random.random((10, 256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model = final_model(input_shape, patch_size, embed_dim, num_heads, window_size, dropout_rate, qkv_bias, num_mlp, shift_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K.clear_session()\n",
    "# # log_dir = f\"{os.environ['tb_path']}segmentation/res50_baseline_bs_128_is_32/\"\n",
    "# # if os.path.exists(log_dir) == False:\n",
    "# #     os.makedirs(log_dir)\n",
    "# # tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir)\n",
    "# weights_path = f'../../weights_mayo_strip_ai/swin_version_1/'\n",
    "# weights_save = CallbackForSavingModelWeights(weights_path)\n",
    "# batch_size = 4\n",
    "# train_dataset = get_data(train, batch_size=batch_size)\n",
    "# val_dataset = get_data(val, shuffle=False, repeat=False, batch_size=batch_size)\n",
    "# # model_config_file\n",
    "# input_shape = (256, 256, 3)\n",
    "# patch_size = (2, 2)\n",
    "# num_patch_x = input_shape[0] // patch_size[0]\n",
    "# num_patch_y = input_shape[1] // patch_size[1]\n",
    "# embed_dim = 128\n",
    "# num_heads = 16\n",
    "# window_size = 2\n",
    "# dropout_rate = 0.0\n",
    "# qkv_bias = False\n",
    "# num_mlp = 1024\n",
    "# shift_size = 1\n",
    "# with strategy.scope():\n",
    "#     model = final_model(input_shape, patch_size, embed_dim, num_heads, window_size, dropout_rate, qkv_bias, num_mlp, shift_size)\n",
    "# wandb.init(\n",
    "#     project = 'mayo_strip_ai',\n",
    "#     # Please add number of epochs\n",
    "#     config = {\n",
    "#         'input_shape' : input_shape,\n",
    "#         'patch_size' : patch_size,\n",
    "#         'num_patch_x' : num_patch_x,\n",
    "#         'num_patch_y' : num_patch_y, \n",
    "#         'embed_dim' : embed_dim,\n",
    "#         'num_heads' : num_heads,\n",
    "#         'window_size' : window_size,\n",
    "#         'dropout_rate' : dropout_rate,\n",
    "#         'qkv_bias' : qkv_bias,\n",
    "#         'num_mlp' : num_mlp,\n",
    "#         'shift_size' : shift_size,\n",
    "#         'optim' : model.optimizer,\n",
    "#         'batch_size' : batch_size,\n",
    "#     }\n",
    "# )\n",
    "# # model traning loop\n",
    "# with strategy.scope():\n",
    "#     model_hist = model.fit(\n",
    "#         train_dataset,\n",
    "#         steps_per_epoch = len(train) // (batch_size * REPLICAS),\n",
    "#         epochs = 100,\n",
    "#         verbose = 1,\n",
    "#         validation_data = val_dataset,\n",
    "#         # callbacks = [tensorboard_callback]\n",
    "#         callbacks = [\n",
    "#             WandbMetricsLogger()\n",
    "#         ]\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:cut7aib5) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅▄▃▂▂▂▂▁▁▁▁</td></tr><tr><td>epoch/prec</td><td>▂▁▂▁▂▂▁▂▁▁▂▁▁▁▂▂▁▂▂▃▄▅▇▇▇▇████</td></tr><tr><td>epoch/rec</td><td>▁████████████████▆▇▇▆▆▇▇█▇████</td></tr><tr><td>epoch/val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▄▃▅▅▇▇█</td></tr><tr><td>epoch/val_prec</td><td>▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▇▄▁▂▅▄▅▃▅▃</td></tr><tr><td>epoch/val_rec</td><td>████████████████████▇▆▂▁▅▂▄▄▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>29</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.02502</td></tr><tr><td>epoch/prec</td><td>0.99012</td></tr><tr><td>epoch/rec</td><td>1.0</td></tr><tr><td>epoch/val_loss</td><td>2.53634</td></tr><tr><td>epoch/val_prec</td><td>0.70968</td></tr><tr><td>epoch/val_rec</td><td>0.84615</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">golden-voice-34</strong> at: <a href='https://wandb.ai/yashchks87/mayo_strip_ai/runs/cut7aib5' target=\"_blank\">https://wandb.ai/yashchks87/mayo_strip_ai/runs/cut7aib5</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230731_013001-cut7aib5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:cut7aib5). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/paperspace/Documents/mayo_strip_ai/notebooks/wandb/run-20230731_013907-6warm89e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yashchks87/mayo_strip_ai/runs/6warm89e' target=\"_blank\">hardy-paper-35</a></strong> to <a href='https://wandb.ai/yashchks87/mayo_strip_ai' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yashchks87/mayo_strip_ai' target=\"_blank\">https://wandb.ai/yashchks87/mayo_strip_ai</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yashchks87/mayo_strip_ai/runs/6warm89e' target=\"_blank\">https://wandb.ai/yashchks87/mayo_strip_ai/runs/6warm89e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "68/68 [==============================] - 18s 173ms/step - loss: 0.6239 - prec: 0.7344 - rec: 0.9438 - val_loss: 0.6751 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 2/30\n",
      "68/68 [==============================] - 10s 146ms/step - loss: 0.6156 - prec: 0.7338 - rec: 1.0000 - val_loss: 0.5943 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 3/30\n",
      "68/68 [==============================] - 10s 145ms/step - loss: 0.6376 - prec: 0.7117 - rec: 0.9647 - val_loss: 0.6069 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 4/30\n",
      "68/68 [==============================] - 10s 146ms/step - loss: 0.5820 - prec: 0.7368 - rec: 1.0000 - val_loss: 0.6055 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 5/30\n",
      "68/68 [==============================] - 10s 145ms/step - loss: 0.6176 - prec: 0.7059 - rec: 1.0000 - val_loss: 0.6164 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 6/30\n",
      "68/68 [==============================] - 10s 145ms/step - loss: 0.5972 - prec: 0.7250 - rec: 1.0000 - val_loss: 0.5963 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 7/30\n",
      "68/68 [==============================] - 10s 146ms/step - loss: 0.5906 - prec: 0.7279 - rec: 1.0000 - val_loss: 0.5934 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 8/30\n",
      "68/68 [==============================] - 10s 145ms/step - loss: 0.6060 - prec: 0.7191 - rec: 1.0000 - val_loss: 0.6058 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 9/30\n",
      "68/68 [==============================] - 10s 145ms/step - loss: 0.5930 - prec: 0.7250 - rec: 1.0000 - val_loss: 0.6044 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 10/30\n",
      "68/68 [==============================] - 10s 146ms/step - loss: 0.6195 - prec: 0.7088 - rec: 1.0000 - val_loss: 0.5903 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 11/30\n",
      "68/68 [==============================] - 10s 146ms/step - loss: 0.5949 - prec: 0.7235 - rec: 1.0000 - val_loss: 0.5915 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 12/30\n",
      "68/68 [==============================] - 10s 145ms/step - loss: 0.5812 - prec: 0.7324 - rec: 1.0000 - val_loss: 0.5936 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 13/30\n",
      "68/68 [==============================] - 10s 146ms/step - loss: 0.6039 - prec: 0.7189 - rec: 0.9959 - val_loss: 0.6020 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 14/30\n",
      "68/68 [==============================] - 10s 147ms/step - loss: 0.5867 - prec: 0.7294 - rec: 1.0000 - val_loss: 0.5890 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 15/30\n",
      "68/68 [==============================] - 10s 147ms/step - loss: 0.5909 - prec: 0.7324 - rec: 1.0000 - val_loss: 0.5930 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 16/30\n",
      "68/68 [==============================] - 10s 148ms/step - loss: 0.5884 - prec: 0.7176 - rec: 1.0000 - val_loss: 0.5883 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 17/30\n",
      "68/68 [==============================] - 10s 148ms/step - loss: 0.5765 - prec: 0.7353 - rec: 1.0000 - val_loss: 0.5870 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 18/30\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.5738 - prec: 0.7247 - rec: 0.9858 - val_loss: 0.5953 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 19/30\n",
      "68/68 [==============================] - 10s 148ms/step - loss: 0.6192 - prec: 0.7006 - rec: 0.9538 - val_loss: 0.5883 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 20/30\n",
      "68/68 [==============================] - 10s 148ms/step - loss: 0.5187 - prec: 0.7500 - rec: 0.9960 - val_loss: 0.5786 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 21/30\n",
      "68/68 [==============================] - 10s 148ms/step - loss: 0.5229 - prec: 0.7410 - rec: 0.9854 - val_loss: 0.5845 - val_prec: 0.7419 - val_rec: 0.8846\n",
      "Epoch 22/30\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.4041 - prec: 0.8274 - rec: 0.9798 - val_loss: 0.6523 - val_prec: 0.7647 - val_rec: 1.0000\n",
      "Epoch 23/30\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.3308 - prec: 0.8649 - rec: 0.9756 - val_loss: 0.7040 - val_prec: 0.7419 - val_rec: 0.8846\n",
      "Epoch 24/30\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.2374 - prec: 0.9128 - rec: 0.9840 - val_loss: 0.8747 - val_prec: 0.7857 - val_rec: 0.8462\n",
      "Epoch 25/30\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.1758 - prec: 0.9409 - rec: 0.9815 - val_loss: 1.0724 - val_prec: 0.7419 - val_rec: 0.8846\n",
      "Epoch 26/30\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.1482 - prec: 0.9456 - rec: 0.9799 - val_loss: 1.3009 - val_prec: 0.6923 - val_rec: 0.6923\n",
      "Epoch 27/30\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.0662 - prec: 0.9796 - rec: 0.9958 - val_loss: 1.1199 - val_prec: 0.7333 - val_rec: 0.8462\n",
      "Epoch 28/30\n",
      "68/68 [==============================] - 10s 151ms/step - loss: 0.0492 - prec: 0.9862 - rec: 0.9960 - val_loss: 1.6270 - val_prec: 0.7241 - val_rec: 0.8077\n",
      "Epoch 29/30\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.1120 - prec: 0.9643 - rec: 0.9898 - val_loss: 1.2612 - val_prec: 0.7097 - val_rec: 0.8462\n",
      "Epoch 30/30\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.0404 - prec: 0.9937 - rec: 0.9917 - val_loss: 1.7701 - val_prec: 0.7188 - val_rec: 0.8846\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "# log_dir = f\"{os.environ['tb_path']}segmentation/res50_baseline_bs_128_is_32/\"\n",
    "# if os.path.exists(log_dir) == False:\n",
    "#     os.makedirs(log_dir)\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir)\n",
    "weights_path = f'../../weights_mayo_strip_ai/swin_version_2/'\n",
    "weights_save = CallbackForSavingModelWeights(weights_path)\n",
    "batch_size = 10\n",
    "train_dataset = get_data(train, train=True, batch_size=batch_size)\n",
    "val_dataset = get_data(val, train = False, shuffle=False, repeat=False, batch_size=batch_size)\n",
    "# model_config_file\n",
    "input_shape = (256, 256, 3)\n",
    "patch_size = (2, 2)\n",
    "num_patch_x = input_shape[0] // patch_size[0]\n",
    "num_patch_y = input_shape[1] // patch_size[1]\n",
    "embed_dim = 32\n",
    "num_heads = 4\n",
    "window_size = 2\n",
    "dropout_rate = 0.0\n",
    "qkv_bias = True\n",
    "num_mlp = 32\n",
    "shift_size = 1\n",
    "with strategy.scope():\n",
    "    model = final_model(input_shape, patch_size, embed_dim, num_heads, window_size, dropout_rate, qkv_bias, num_mlp, shift_size)\n",
    "wandb.init(\n",
    "    project = 'mayo_strip_ai',\n",
    "    # Please add number of epochs\n",
    "    config = {\n",
    "        'input_shape' : input_shape,\n",
    "        'patch_size' : patch_size,\n",
    "        'num_patch_x' : num_patch_x,\n",
    "        'num_patch_y' : num_patch_y, \n",
    "        'embed_dim' : embed_dim,\n",
    "        'num_heads' : num_heads,\n",
    "        'window_size' : window_size,\n",
    "        'dropout_rate' : dropout_rate,\n",
    "        'qkv_bias' : qkv_bias,\n",
    "        'num_mlp' : num_mlp,\n",
    "        'shift_size' : shift_size,\n",
    "        'optim' : model.optimizer,\n",
    "        'batch_size' : batch_size,\n",
    "        'augmentations' : ('Random flip left-right', 'Gradient clipping 1.0')\n",
    "    }\n",
    ")\n",
    "# model traning loop\n",
    "with strategy.scope():\n",
    "    model_hist = model.fit(\n",
    "        train_dataset,\n",
    "        steps_per_epoch = len(train) // (batch_size * REPLICAS),\n",
    "        epochs = 30,\n",
    "        verbose = 1,\n",
    "        validation_data = val_dataset,\n",
    "        # callbacks = [tensorboard_callback]\n",
    "        callbacks = [\n",
    "            WandbMetricsLogger(),\n",
    "            weights_save\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = final_model(input_shape, patch_size, embed_dim, num_heads, window_size, dropout_rate, qkv_bias, num_mlp, shift_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../../weights_mayo_strip_ai/swin_version_2/21.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = get_data(val, train = False, shuffle=False, repeat=False, batch_size=batch_size)\n",
    "test_dataset = get_data(test, train = False, shuffle=False, repeat=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 63ms/step - loss: 0.5632 - prec: 0.7500 - rec: 0.9231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5631629228591919, 0.75, 0.9230769276618958]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 66ms/step - loss: 0.5961 - prec: 0.7500 - rec: 0.9310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5961013436317444, 0.75, 0.931034505367279]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:27yikwdb) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▅▄▃▂▂▁▁▁▁</td></tr><tr><td>epoch/prec</td><td>▂▁▂▂▂▁▁▂▁▂▂▂▂▁▂▁▂▁▂▁▃▄▅▆▇▇████</td></tr><tr><td>epoch/rec</td><td>▁███▆███▅▆███████▇██▆▇▇▆██████</td></tr><tr><td>epoch/val_loss</td><td>▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▂▁▂▁▂▄▅▆▅█▅▄▂</td></tr><tr><td>epoch/val_prec</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▃▄▄▂▃▂█▁▄</td></tr><tr><td>epoch/val_rec</td><td>███████████████████▁█▇▇▇▆▅█▅▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>29</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.10153</td></tr><tr><td>epoch/prec</td><td>0.99197</td></tr><tr><td>epoch/rec</td><td>1.0</td></tr><tr><td>epoch/val_loss</td><td>0.71782</td></tr><tr><td>epoch/val_prec</td><td>0.75758</td></tr><tr><td>epoch/val_rec</td><td>0.96154</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rare-eon-37</strong> at: <a href='https://wandb.ai/yashchks87/mayo_strip_ai/runs/27yikwdb' target=\"_blank\">https://wandb.ai/yashchks87/mayo_strip_ai/runs/27yikwdb</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230731_015502-27yikwdb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:27yikwdb). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/paperspace/Documents/mayo_strip_ai/notebooks/wandb/run-20230731_020032-y941c3af</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yashchks87/mayo_strip_ai/runs/y941c3af' target=\"_blank\">atomic-leaf-38</a></strong> to <a href='https://wandb.ai/yashchks87/mayo_strip_ai' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yashchks87/mayo_strip_ai' target=\"_blank\">https://wandb.ai/yashchks87/mayo_strip_ai</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yashchks87/mayo_strip_ai/runs/y941c3af' target=\"_blank\">https://wandb.ai/yashchks87/mayo_strip_ai/runs/y941c3af</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      " 6/68 [=>............................] - ETA: 8s - loss: 1.2167 - prec: 0.6047 - rec: 0.7027WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0723s vs `on_train_batch_end` time: 0.0727s). Check your callbacks.\n",
      "68/68 [==============================] - 18s 174ms/step - loss: 0.7019 - prec: 0.7127 - rec: 0.9155 - val_loss: 0.6003 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 2/60\n",
      "68/68 [==============================] - 10s 145ms/step - loss: 0.5844 - prec: 0.7485 - rec: 1.0000 - val_loss: 0.6938 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 3/60\n",
      "68/68 [==============================] - 10s 146ms/step - loss: 0.6238 - prec: 0.7088 - rec: 1.0000 - val_loss: 0.6240 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 4/60\n",
      "68/68 [==============================] - 10s 146ms/step - loss: 0.6060 - prec: 0.7191 - rec: 1.0000 - val_loss: 0.6032 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 5/60\n",
      "68/68 [==============================] - 10s 145ms/step - loss: 0.6209 - prec: 0.7265 - rec: 0.9798 - val_loss: 0.5965 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 6/60\n",
      "68/68 [==============================] - 10s 147ms/step - loss: 0.6108 - prec: 0.7338 - rec: 1.0000 - val_loss: 0.6005 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 7/60\n",
      "68/68 [==============================] - 10s 148ms/step - loss: 0.6146 - prec: 0.7149 - rec: 0.9650 - val_loss: 0.6144 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 8/60\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.5982 - prec: 0.7250 - rec: 1.0000 - val_loss: 0.6043 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 9/60\n",
      "68/68 [==============================] - 10s 148ms/step - loss: 0.6037 - prec: 0.7206 - rec: 1.0000 - val_loss: 0.6036 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 10/60\n",
      "68/68 [==============================] - 10s 148ms/step - loss: 0.6074 - prec: 0.7191 - rec: 1.0000 - val_loss: 0.6018 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 11/60\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.5916 - prec: 0.7426 - rec: 1.0000 - val_loss: 0.6122 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 12/60\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.6165 - prec: 0.7044 - rec: 1.0000 - val_loss: 0.5973 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 13/60\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.5900 - prec: 0.7368 - rec: 1.0000 - val_loss: 0.6008 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 14/60\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.6028 - prec: 0.7279 - rec: 1.0000 - val_loss: 0.5959 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 15/60\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.6155 - prec: 0.7108 - rec: 0.9772 - val_loss: 0.6573 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 16/60\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.6151 - prec: 0.7191 - rec: 1.0000 - val_loss: 0.5977 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 17/60\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.5936 - prec: 0.7324 - rec: 1.0000 - val_loss: 0.6160 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 18/60\n",
      "68/68 [==============================] - 10s 150ms/step - loss: 0.6026 - prec: 0.7324 - rec: 1.0000 - val_loss: 0.6016 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 19/60\n",
      "68/68 [==============================] - 10s 150ms/step - loss: 0.6080 - prec: 0.7059 - rec: 1.0000 - val_loss: 0.5925 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 20/60\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.5976 - prec: 0.7235 - rec: 1.0000 - val_loss: 0.6264 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 21/60\n",
      "68/68 [==============================] - 10s 151ms/step - loss: 0.5879 - prec: 0.7294 - rec: 1.0000 - val_loss: 0.5974 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 22/60\n",
      "68/68 [==============================] - 10s 151ms/step - loss: 0.5820 - prec: 0.7235 - rec: 1.0000 - val_loss: 0.5881 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 23/60\n",
      "68/68 [==============================] - 10s 148ms/step - loss: 0.5599 - prec: 0.7322 - rec: 0.9980 - val_loss: 0.6121 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 24/60\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.5277 - prec: 0.7565 - rec: 0.9900 - val_loss: 0.6859 - val_prec: 0.7222 - val_rec: 1.0000\n",
      "Epoch 25/60\n",
      "68/68 [==============================] - 10s 150ms/step - loss: 0.5062 - prec: 0.7699 - rec: 0.9627 - val_loss: 0.7054 - val_prec: 0.7333 - val_rec: 0.8462\n",
      "Epoch 26/60\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.4423 - prec: 0.8124 - rec: 0.9593 - val_loss: 0.8653 - val_prec: 0.7083 - val_rec: 0.6538\n",
      "Epoch 27/60\n",
      "68/68 [==============================] - 10s 151ms/step - loss: 0.3472 - prec: 0.8755 - rec: 0.9554 - val_loss: 1.1072 - val_prec: 0.7273 - val_rec: 0.9231\n",
      "Epoch 28/60\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.2898 - prec: 0.9076 - rec: 0.9781 - val_loss: 1.0434 - val_prec: 0.7353 - val_rec: 0.9615\n",
      "Epoch 29/60\n",
      "68/68 [==============================] - 10s 150ms/step - loss: 0.2013 - prec: 0.9470 - rec: 0.9857 - val_loss: 1.2890 - val_prec: 0.7308 - val_rec: 0.7308\n",
      "Epoch 30/60\n",
      "68/68 [==============================] - 10s 150ms/step - loss: 0.1543 - prec: 0.9678 - rec: 0.9959 - val_loss: 1.3820 - val_prec: 0.7407 - val_rec: 0.7692\n",
      "Epoch 31/60\n",
      "68/68 [==============================] - 10s 151ms/step - loss: 0.1474 - prec: 0.9702 - rec: 0.9919 - val_loss: 1.5073 - val_prec: 0.7241 - val_rec: 0.8077\n",
      "Epoch 32/60\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.1469 - prec: 0.9725 - rec: 0.9960 - val_loss: 1.1987 - val_prec: 0.7586 - val_rec: 0.8462\n",
      "Epoch 33/60\n",
      "68/68 [==============================] - 10s 150ms/step - loss: 0.1228 - prec: 0.9816 - rec: 0.9979 - val_loss: 1.3306 - val_prec: 0.7241 - val_rec: 0.8077\n",
      "Epoch 34/60\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.1090 - prec: 0.9880 - rec: 1.0000 - val_loss: 1.4961 - val_prec: 0.7419 - val_rec: 0.8846\n",
      "Epoch 35/60\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.1059 - prec: 0.9902 - rec: 1.0000 - val_loss: 1.4417 - val_prec: 0.7500 - val_rec: 0.8077\n",
      "Epoch 36/60\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.0994 - prec: 0.9939 - rec: 0.9979 - val_loss: 1.1897 - val_prec: 0.7419 - val_rec: 0.8846\n",
      "Epoch 37/60\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.0968 - prec: 0.9940 - rec: 0.9980 - val_loss: 1.3325 - val_prec: 0.7586 - val_rec: 0.8462\n",
      "Epoch 38/60\n",
      "68/68 [==============================] - 10s 151ms/step - loss: 0.0999 - prec: 0.9918 - rec: 1.0000 - val_loss: 1.5109 - val_prec: 0.7500 - val_rec: 0.8077\n",
      "Epoch 39/60\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.0886 - prec: 1.0000 - rec: 1.0000 - val_loss: 1.3868 - val_prec: 0.7241 - val_rec: 0.8077\n",
      "Epoch 40/60\n",
      "68/68 [==============================] - 10s 150ms/step - loss: 0.0913 - prec: 0.9940 - rec: 1.0000 - val_loss: 1.1738 - val_prec: 0.7586 - val_rec: 0.8462\n",
      "Epoch 41/60\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.0861 - prec: 0.9980 - rec: 1.0000 - val_loss: 1.4112 - val_prec: 0.7333 - val_rec: 0.8462\n",
      "Epoch 42/60\n",
      "68/68 [==============================] - 10s 150ms/step - loss: 0.0887 - prec: 0.9959 - rec: 1.0000 - val_loss: 1.2947 - val_prec: 0.7500 - val_rec: 0.9231\n",
      "Epoch 43/60\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.0835 - prec: 1.0000 - rec: 1.0000 - val_loss: 1.4194 - val_prec: 0.7241 - val_rec: 0.8077\n",
      "Epoch 44/60\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.0874 - prec: 0.9959 - rec: 1.0000 - val_loss: 1.3652 - val_prec: 0.7241 - val_rec: 0.8077\n",
      "Epoch 45/60\n",
      "68/68 [==============================] - 10s 150ms/step - loss: 0.0850 - prec: 0.9980 - rec: 1.0000 - val_loss: 1.3887 - val_prec: 0.7308 - val_rec: 0.7308\n",
      "Epoch 46/60\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.0824 - prec: 1.0000 - rec: 1.0000 - val_loss: 1.2981 - val_prec: 0.7333 - val_rec: 0.8462\n",
      "Epoch 47/60\n",
      "68/68 [==============================] - 10s 150ms/step - loss: 0.0845 - prec: 0.9980 - rec: 1.0000 - val_loss: 1.3918 - val_prec: 0.7500 - val_rec: 0.9231\n",
      "Epoch 48/60\n",
      "68/68 [==============================] - 10s 150ms/step - loss: 0.0833 - prec: 0.9980 - rec: 1.0000 - val_loss: 1.3357 - val_prec: 0.7241 - val_rec: 0.8077\n",
      "Epoch 49/60\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.0831 - prec: 0.9980 - rec: 1.0000 - val_loss: 1.2982 - val_prec: 0.7241 - val_rec: 0.8077\n",
      "Epoch 50/60\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.0863 - prec: 0.9959 - rec: 1.0000 - val_loss: 1.4226 - val_prec: 0.7333 - val_rec: 0.8462\n",
      "Epoch 51/60\n",
      "68/68 [==============================] - 10s 150ms/step - loss: 0.0824 - prec: 1.0000 - rec: 1.0000 - val_loss: 1.2528 - val_prec: 0.7143 - val_rec: 0.7692\n",
      "Epoch 52/60\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.0851 - prec: 0.9980 - rec: 1.0000 - val_loss: 1.3999 - val_prec: 0.7188 - val_rec: 0.8846\n",
      "Epoch 53/60\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.0857 - prec: 0.9980 - rec: 1.0000 - val_loss: 1.5819 - val_prec: 0.7143 - val_rec: 0.7692\n",
      "Epoch 54/60\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.0891 - prec: 0.9959 - rec: 1.0000 - val_loss: 1.4026 - val_prec: 0.7333 - val_rec: 0.8462\n",
      "Epoch 55/60\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.0887 - prec: 0.9980 - rec: 1.0000 - val_loss: 1.5531 - val_prec: 0.7037 - val_rec: 0.7308\n",
      "Epoch 56/60\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.0921 - prec: 0.9960 - rec: 1.0000 - val_loss: 1.4384 - val_prec: 0.7586 - val_rec: 0.8462\n",
      "Epoch 57/60\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.0855 - prec: 1.0000 - rec: 1.0000 - val_loss: 1.6481 - val_prec: 0.7037 - val_rec: 0.7308\n",
      "Epoch 58/60\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.0887 - prec: 0.9960 - rec: 1.0000 - val_loss: 1.5083 - val_prec: 0.7143 - val_rec: 0.7692\n",
      "Epoch 59/60\n",
      "68/68 [==============================] - 10s 149ms/step - loss: 0.0839 - prec: 1.0000 - rec: 1.0000 - val_loss: 1.3960 - val_prec: 0.7333 - val_rec: 0.8462\n",
      "Epoch 60/60\n",
      "68/68 [==============================] - 10s 150ms/step - loss: 0.0870 - prec: 0.9958 - rec: 1.0000 - val_loss: 1.4373 - val_prec: 0.7667 - val_rec: 0.8846\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "weights_path = f'../../weights_mayo_strip_ai/swin_version_2_ls/'\n",
    "weights_save = CallbackForSavingModelWeights(weights_path)\n",
    "batch_size = 10\n",
    "train_dataset = get_data(train, train=True, batch_size=batch_size)\n",
    "val_dataset = get_data(val, train = False, shuffle=False, repeat=False, batch_size=batch_size)\n",
    "# model_config_file\n",
    "input_shape = (256, 256, 3)\n",
    "patch_size = (2, 2)\n",
    "num_patch_x = input_shape[0] // patch_size[0]\n",
    "num_patch_y = input_shape[1] // patch_size[1]\n",
    "embed_dim = 32\n",
    "num_heads = 4\n",
    "window_size = 2\n",
    "dropout_rate = 0.0\n",
    "qkv_bias = True\n",
    "num_mlp = 32\n",
    "shift_size = 1\n",
    "with strategy.scope():\n",
    "    model = final_model(input_shape, patch_size, embed_dim, num_heads, window_size, dropout_rate, qkv_bias, num_mlp, shift_size)\n",
    "wandb.init(\n",
    "    project = 'mayo_strip_ai',\n",
    "    # Please add number of epochs\n",
    "    config = {\n",
    "        'input_shape' : input_shape,\n",
    "        'patch_size' : patch_size,\n",
    "        'num_patch_x' : num_patch_x,\n",
    "        'num_patch_y' : num_patch_y, \n",
    "        'embed_dim' : embed_dim,\n",
    "        'num_heads' : num_heads,\n",
    "        'window_size' : window_size,\n",
    "        'dropout_rate' : dropout_rate,\n",
    "        'qkv_bias' : qkv_bias,\n",
    "        'num_mlp' : num_mlp,\n",
    "        'shift_size' : shift_size,\n",
    "        'optim' : model.optimizer,\n",
    "        'batch_size' : batch_size,\n",
    "        'augmentations' : ('Random flip left-right', 'Gradient clipping 1.0'),\n",
    "        'label_smoothing' : 0.03\n",
    "    }\n",
    ")\n",
    "# model traning loop\n",
    "with strategy.scope():\n",
    "    model_hist = model.fit(\n",
    "        train_dataset,\n",
    "        steps_per_epoch = len(train) // (batch_size * REPLICAS),\n",
    "        epochs = 60,\n",
    "        verbose = 1,\n",
    "        validation_data = val_dataset,\n",
    "        # callbacks = [tensorboard_callback]\n",
    "        callbacks = [\n",
    "            WandbMetricsLogger(),\n",
    "            weights_save\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_env",
   "language": "python",
   "name": "tensor_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
